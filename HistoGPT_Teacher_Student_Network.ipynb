{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyileiaye2021/HistoGPT-Teacher-Student-Network/blob/main/HistoGPT_Teacher_Student_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StkPp5VXN48S"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNphB3ACN6aO",
        "outputId": "c5bbc12f-fe09-45c3-e5cd-5344511da436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libopenslide0\n",
            "Suggested packages:\n",
            "  libtiff-tools\n",
            "The following NEW packages will be installed:\n",
            "  libopenslide0 openslide-tools\n",
            "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 104 kB of archives.\n",
            "After this operation, 297 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenslide0 amd64 3.4.1+dfsg-5build1 [89.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 openslide-tools amd64 3.4.1+dfsg-5build1 [13.8 kB]\n",
            "Fetched 104 kB in 1s (202 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libopenslide0.\n",
            "(Reading database ... 126374 files and directories currently installed.)\n",
            "Preparing to unpack .../libopenslide0_3.4.1+dfsg-5build1_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-5build1) ...\n",
            "Selecting previously unselected package openslide-tools.\n",
            "Preparing to unpack .../openslide-tools_3.4.1+dfsg-5build1_amd64.deb ...\n",
            "Unpacking openslide-tools (3.4.1+dfsg-5build1) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-5build1) ...\n",
            "Setting up openslide-tools (3.4.1+dfsg-5build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-openslide\n",
            "Collecting openslide-python\n",
            "  Downloading openslide_python-1.4.2-cp311-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from openslide-python) (11.3.0)\n",
            "Downloading openslide_python-1.4.2-cp311-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.whl (36 kB)\n",
            "Installing collected packages: openslide-python\n",
            "Successfully installed openslide-python-1.4.2\n"
          ]
        }
      ],
      "source": [
        "# install openslide dependencies\n",
        "!sudo apt-get install openslide-tools\n",
        "!sudo apt-get install python-openslide\n",
        "!pip install openslide-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia7hnIXeN8Iv",
        "outputId": "69cf5265-2549-4415-de05-4f3db6d2e2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flamingo-pytorch\n",
            "  Downloading flamingo_pytorch-0.1.2-py3-none-any.whl.metadata (727 bytes)\n",
            "Downloading flamingo_pytorch-0.1.2-py3-none-any.whl (7.8 kB)\n",
            "Installing collected packages: flamingo-pytorch\n",
            "Successfully installed flamingo-pytorch-0.1.2\n",
            "Collecting git+https://github.com/marrlab/HistoGPT.git\n",
            "  Cloning https://github.com/marrlab/HistoGPT.git to /tmp/pip-req-build-x63ngd4h\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/marrlab/HistoGPT.git /tmp/pip-req-build-x63ngd4h\n",
            "  Resolved https://github.com/marrlab/HistoGPT.git to commit 35feddc2b5833676e9e8f09ee432b548a2a75e46\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops>=0.4 in /usr/local/lib/python3.12/dist-packages (from histogpt==1.1.2) (0.8.1)\n",
            "Collecting einops-exts (from histogpt==1.1.2)\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from histogpt==1.1.2) (1.106.1)\n",
            "Collecting sacremoses>=0.1.1 (from histogpt==1.1.2)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting slideio>=2.7.1 (from histogpt==1.1.2)\n",
            "  Downloading slideio-2.7.3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from histogpt==1.1.2) (2.8.0+cu126)\n",
            "Collecting transformers==4.38.2 (from histogpt==1.1.2)\n",
            "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->histogpt==1.1.2) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->histogpt==1.1.2) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->histogpt==1.1.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->histogpt==1.1.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->histogpt==1.1.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->histogpt==1.1.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->histogpt==1.1.2) (2.32.4)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2->histogpt==1.1.2)\n",
            "  Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->histogpt==1.1.2) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->histogpt==1.1.2) (4.67.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->histogpt==1.1.2) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->histogpt==1.1.2) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->histogpt==1.1.2) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->histogpt==1.1.2) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->histogpt==1.1.2) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->histogpt==1.1.2) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->histogpt==1.1.2) (4.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from sacremoses>=0.1.1->histogpt==1.1.2) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from sacremoses>=0.1.1->histogpt==1.1.2) (1.5.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->histogpt==1.1.2) (3.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.14.0->histogpt==1.1.2) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.14.0->histogpt==1.1.2) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.14.0->histogpt==1.1.2) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.14.0->histogpt==1.1.2) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->histogpt==1.1.2) (1.1.9)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.14.0->histogpt==1.1.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.14.0->histogpt==1.1.2) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.14.0->histogpt==1.1.2) (0.4.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->histogpt==1.1.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->histogpt==1.1.2) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2->histogpt==1.1.2) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2->histogpt==1.1.2) (2.5.0)\n",
            "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading slideio-2.7.3-cp312-cp312-manylinux_2_28_x86_64.whl (53.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: histogpt\n",
            "  Building wheel for histogpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for histogpt: filename=histogpt-1.1.2-py3-none-any.whl size=74240 sha256=c09f21036b100d45883e239d16600079d2535ca8523fa815a43f55444a8b0c2b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2yn6m5ff/wheels/20/af/4e/1bc038e06f5240dbf16f45c0777256bd5fafe10435fc73d199\n",
            "Successfully built histogpt\n",
            "Installing collected packages: slideio, sacremoses, einops-exts, tokenizers, transformers, histogpt\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.0\n",
            "    Uninstalling tokenizers-0.22.0:\n",
            "      Successfully uninstalled tokenizers-0.22.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.1\n",
            "    Uninstalling transformers-4.56.1:\n",
            "      Successfully uninstalled transformers-4.56.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed einops-exts-0.0.4 histogpt-1.1.2 sacremoses-0.1.1 slideio-2.7.3 tokenizers-0.15.2 transformers-4.38.2\n"
          ]
        }
      ],
      "source": [
        "# install flamingo and histogpt\n",
        "!pip install flamingo-pytorch --no-deps\n",
        "!pip install git+https://github.com/marrlab/HistoGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8BvX7TzN-cj",
        "outputId": "973ac000-518d-4e55-9325-f6450f7dce9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# check whether to use a gpu or cpu\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNxbldYKOCSb"
      },
      "source": [
        "# Mounting the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JOSUz_pOFAy",
        "outputId": "524b334a-2668-4f04-b394-f3ca73a730f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsGuQ7agOG3q"
      },
      "source": [
        "# Load the HistoGPT Teacher model (original model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDubaCxqOf63"
      },
      "outputs": [],
      "source": [
        "from transformers import BioGptConfig\n",
        "from histogpt.models import HistoGPTForCausalLM, PerceiverResamplerConfig\n",
        "\n",
        "histogpt_teacher = HistoGPTForCausalLM(BioGptConfig(), PerceiverResamplerConfig())\n",
        "histogpt_teacher = histogpt_teacher.to(device)\n",
        "PATH = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Histogpt_weights/histogpt-1b-6k-pruned.pth' # histogpt weight\n",
        "state_dict = torch.load(PATH, map_location=device)\n",
        "histogpt_teacher.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXsCYrsSO0nx"
      },
      "source": [
        "# Checking HistoGPT Teacher model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrQCYAaEOrOD"
      },
      "outputs": [],
      "source": [
        "for name, param in histogpt_teacher.named_parameters():\n",
        "    print(name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrZMXdDuYa0J"
      },
      "source": [
        "# Freezing All Trainable Parameters in HistoGPT Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9dqjb84QJOy"
      },
      "outputs": [],
      "source": [
        "# Freezing all parameters\n",
        "for param in histogpt_teacher.parameters():\n",
        "    param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDGwHEpddGb1"
      },
      "outputs": [],
      "source": [
        "# check if all parameters are freezed\n",
        "for name, param in histogpt_teacher.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs7Iv3uil3p8"
      },
      "source": [
        "# Loading HistoGPT Student Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N-E46F7gm9M",
        "outputId": "4193f5f0-e5fc-4c1d-c9f0-2ffa86502c33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from transformers import BioGptConfig\n",
        "from histogpt.models import HistoGPTForCausalLM, PerceiverResamplerConfig\n",
        "\n",
        "histogpt_student = HistoGPTForCausalLM(BioGptConfig(), PerceiverResamplerConfig())\n",
        "histogpt_student = histogpt_student.to(device)\n",
        "PATH = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Histogpt_weights/histogpt-1b-6k-pruned.pth' # histogpt weight\n",
        "state_dict = torch.load(PATH, map_location=device)\n",
        "histogpt_student.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPxZoAVummMV"
      },
      "source": [
        "# Unfreezing Certain Parameters in HistoGPT Student Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gqw-ZY9kmy9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a1b13f-13a6-4654-e650-c3852941c47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2752512\n"
          ]
        }
      ],
      "source": [
        "# Freezing all parameters first\n",
        "for name, param in histogpt_student.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for name, param in histogpt_student.named_parameters():\n",
        "  # Unfreezing the last layer of perceiver resampler (slide level encoder)\n",
        "  # if 'perceiver_resampler.layers.5' in str(name):\n",
        "  #   param.requires_grad = True\n",
        "\n",
        "  # Unfreezing the exit gate of perceiver resampler\n",
        "  if 'histogpt.perceiver_exitgate.weight' in name:\n",
        "    param.requires_grad = True\n",
        "\n",
        "  # Unfreezing the linear layer of perceiver sampler\n",
        "  if 'perceiver_resampler.linear' in str(name):\n",
        "    param.requires_grad = True\n",
        "\n",
        "total_params = 0\n",
        "for name, param in histogpt_student.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    total_params += param.numel()\n",
        "print(total_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVoEFyweqgFH",
        "outputId": "90710bc2-8b9b-416c-bae3-c601e9d87201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "histogpt.perceiver_resampler.linear.weight\n",
            "histogpt.perceiver_exitgate.weight\n"
          ]
        }
      ],
      "source": [
        "# check if all parameters are freezed\n",
        "for name, param in histogpt_student.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQuN7FxcjsLL"
      },
      "source": [
        "### Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma-ilnvOrxqx"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVtLUoRcimhh"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import os\n",
        "from PIL import Image\n",
        "from timm.data.constants import IMAGENET_INCEPTION_MEAN, IMAGENET_INCEPTION_STD\n",
        "\n",
        "class AugmentedImageDataset(Dataset):\n",
        "  def __init__(self, oct_dir, he_dir):\n",
        "    self.oct_dir = oct_dir\n",
        "    self.he_dir = he_dir\n",
        "\n",
        "    self.paired_files = []\n",
        "    he_files = os.listdir(he_dir)\n",
        "    he_files_lower = {he_file.lower(): he_file for he_file in he_files}\n",
        "    for oct_file in os.listdir(oct_dir):\n",
        "      oct_file_lower = oct_file.lower()\n",
        "\n",
        "      # replace '_real_a' with '_real_b' to find the matching files\n",
        "      if '_real_a' in oct_file_lower:\n",
        "        he_file = oct_file_lower.replace('_real_a', '_real_b')\n",
        "\n",
        "      elif '_fake_a' in oct_file_lower:\n",
        "        he_file = oct_file_lower.replace('_fake_a', '_fake_b')\n",
        "\n",
        "      if he_file in he_files_lower:\n",
        "        he_file = he_files_lower[he_file]\n",
        "        self.paired_files.append((os.path.join(oct_dir, oct_file), os.path.join(he_dir, he_file)))\n",
        "      else:\n",
        "        print(f'Warning: {he_file} not found in {he_dir}')\n",
        "\n",
        "\n",
        "    img_size = 384\n",
        "    self.transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(img_size, interpolation=3, antialias=True),\n",
        "        torchvision.transforms.CenterCrop((img_size, img_size)),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(mean=IMAGENET_INCEPTION_MEAN, std=IMAGENET_INCEPTION_STD)\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paired_files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    oct_path, he_path = self.paired_files[idx] # retrieve the paired (oct, h&e) file names\n",
        "    oct_image = Image.open(oct_path).convert('RGB')\n",
        "    he_image = Image.open(he_path).convert('RGB')\n",
        "\n",
        "    return self.transform(oct_image), self.transform(he_image)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7TuZnlLmyZS"
      },
      "source": [
        "### Prepare Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7r7roykm0bG"
      },
      "outputs": [],
      "source": [
        "# create config dictionary\n",
        "train_config = {\n",
        "    \"train_folder\": \"/content/drive/MyDrive/Teacher_Student_Network/Split Dataset/train\",\n",
        "    \"he_val_folder\": \"/content/drive/MyDrive/Teacher_Student_Network/Split Dataset/he_val\",\n",
        "    \"vhe_val_folder\": \"/content/drive/MyDrive/Teacher_Student_Network/Split Dataset/vhe_val\",\n",
        "    \"batch_size\": 128, # Reduced batch size\n",
        "    \"epochs\": 300,\n",
        "    \"shuffle_train\": True,\n",
        "    \"num_workers\": 2,\n",
        "    \"pin_memory\": True,\n",
        "    \"init_lr\": 1e-6,\n",
        "    \"weight_decay\": 0.05,\n",
        "    \"epochs_between_save\": 5,\n",
        "    \"epochs_between_val\": 5,\n",
        "    \"patience\": 5,  # for early stopping\n",
        "    \"output_dir_path\": \"/content/drive/MyDrive/Teacher_Student_Network/model_savepoints\"\n",
        "}\n",
        "\n",
        "train_oct_folder = os.path.join(train_config['train_folder'],'OCT')\n",
        "train_he_folder = os.path.join(train_config['train_folder'],'H&E')\n",
        "\n",
        "val_he_oct_folder = os.path.join(train_config['he_val_folder'], 'OCT')\n",
        "val_he_folder = os.path.join(train_config['he_val_folder'], 'H&E')\n",
        "val_vhe_oct_folder = os.path.join(train_config['vhe_val_folder'], 'OCT')\n",
        "val_vhe_folder = os.path.join(train_config['vhe_val_folder'], 'vH&E')\n",
        "\n",
        "train_dataset = AugmentedImageDataset(train_oct_folder, train_he_folder)\n",
        "he_val_dataset = AugmentedImageDataset(val_he_oct_folder, val_he_folder)\n",
        "vhe_val_dataset = AugmentedImageDataset(val_vhe_oct_folder, val_vhe_folder)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=train_config['batch_size'],\n",
        "    shuffle=train_config['shuffle_train'],\n",
        "    num_workers=train_config['num_workers'],\n",
        "    pin_memory=train_config['pin_memory']\n",
        ")\n",
        "\n",
        "he_val_loader = DataLoader(\n",
        "    he_val_dataset,\n",
        "    batch_size=train_config['batch_size'],\n",
        "    shuffle=False, # usually false for val\n",
        "    num_workers=train_config['num_workers'],\n",
        "    pin_memory=train_config['pin_memory']\n",
        ")\n",
        "\n",
        "vhe_val_loader = DataLoader(\n",
        "    vhe_val_dataset,\n",
        "    batch_size=train_config['batch_size'],\n",
        "    shuffle=False, # usually false for val\n",
        "    num_workers=train_config['num_workers'],\n",
        "    pin_memory=train_config['pin_memory']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC5i7U6snhra"
      },
      "outputs": [],
      "source": [
        "print(f\"Total number of H&E-OCT pairs batches in each epoch in train set: {len(train_loader)}\")\n",
        "print(f\"Total number of H&E-OCT pairs batches in each epoch in val set: {len(he_val_loader)}\")\n",
        "print(f\"Total number of vH&E-OCT pairs batches in each epoch in val set: {len(vhe_val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwJzUUXoi9KO"
      },
      "source": [
        "### Extracting Embeddings from Perceiver Resampler and Exit Gate\n",
        "The model first extract patch embeddings (n x 768)D using CTransPath patch image encoder and stored in the h5 file. Then, those were the input of perceiver resampler (slide encoder) to generate fixed (640 x 1536)D of image embeddings. After that, that was put into the exit gate (vision + language space) and releases (640 x D_txt)D embeddings. Then, those embeddings are input into tanh gate cross attention block in language module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgHlIx1IulSG"
      },
      "source": [
        "#### Getting Concatenation of Patch Embeddings from CTransPath Image Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UfvpuVQfBneV"
      },
      "outputs": [],
      "source": [
        "### convert grayscale images to RGB 3 channel images\n",
        "import cv2\n",
        "\n",
        "def convert_to_rgb(image_path, save_path):\n",
        "  # loading grayscale images\n",
        "  grayscale_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "  # converting the grayscale to rgb\n",
        "  rgb_img = cv2.cvtColor(grayscale_img, cv2.COLOR_GRAY2RGB)\n",
        "  cv2.imwrite(save_path, rgb_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nnzqRutknEBk"
      },
      "outputs": [],
      "source": [
        "# Combination of patch features of each image will be saved in h5 file\n",
        "import os\n",
        "import shutil\n",
        "from histogpt.helpers.patching import main, PatchingConfigs\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_patch_emb(image_folder, feature_folder, img_type):\n",
        "\n",
        "  configs = PatchingConfigs()\n",
        "  configs.slide_path = image_folder\n",
        "  configs.save_path = feature_folder\n",
        "  configs.file_extension = img_type\n",
        "  configs.model_path = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Ctranspath_weights/ctranspath.pth' # Extracting Patch Image Embeddings from CTransPath Image Encoder\n",
        "  configs.patch_size = 128\n",
        "  configs.white_thresh = [170, 185, 175]\n",
        "  configs.edge_threshold = 2\n",
        "  configs.resolution_in_mpp = 0.0\n",
        "  configs.downscaling_factor = 1.0\n",
        "  # configs.save_patch_images = True\n",
        "  configs.save_tile_preview = True\n",
        "  configs.batch_size = 16\n",
        "  # Use all slides in the folder\n",
        "  configs.split = [0, 1]  # Use all files\n",
        "\n",
        "  main(configs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCf-YonoGkkN"
      },
      "source": [
        "### Getting Slide Embeddings from Perceiver Resampler and Exit Gate (vision + language space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_13fiXyRi8lf"
      },
      "outputs": [],
      "source": [
        "'''Concatenation of patch image embeddings go thru the perceiver resampler (slide encoder)\n",
        "and exit gate (vision + language space) to get slide level embeddings'''\n",
        "\n",
        "from histogpt.models.histogpt import PerceiverResamplerConfig\n",
        "import h5py\n",
        "import os\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "def extract_slide_emb(patch_feature_folder, model):\n",
        "\n",
        "  slide_image_features = {}\n",
        "\n",
        "  for h5_file in os.listdir(patch_feature_folder):\n",
        "    print(h5_file)\n",
        "    if h5_file.endswith('.h5'):\n",
        "      filename = os.path.join(patch_feature_folder, h5_file)\n",
        "      with h5py.File(filename, 'r') as f:\n",
        "        features = f['feats'][:]\n",
        "        features = torch.tensor(features).unsqueeze(0).to(device)\n",
        "\n",
        "        # converting float32 to float16\n",
        "        if 'A' in h5_file:\n",
        "          with autocast(dtype=torch.float16):\n",
        "            latents = model.histogpt.perceiver_resampler(features)\n",
        "\n",
        "        # Perceiver resampler: [B, 1, 640, dim_model]\n",
        "        latents = model.histogpt.perceiver_resampler(features)\n",
        "        model.histogpt.perceiver_resampler.linear()\n",
        "        # Exit gate maps to LM hidden size: [B, 1, 640, D_txt]\n",
        "        media = model.histogpt.perceiver_exitgate(latents)   # what XATTN uses\n",
        "\n",
        "        slide_image_features[h5_file] = media\n",
        "\n",
        "        print(latents.shape)\n",
        "        print(media.shape)\n",
        "        print()\n",
        "\n",
        "  return slide_image_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU94fd1q6Qt5",
        "outputId": "e380fafd-05cf-4c30-88d8-e5f526c2fed7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "slides:   0%|          | 0/315 [00:00<?, ?it/s]\n",
            "LE-03-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   0%|          | 1/315 [00:04<21:40,  4.14s/it]\n",
            "LE-03-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   1%|          | 2/315 [00:07<18:13,  3.49s/it]\n",
            "LE-03-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   1%|          | 3/315 [00:10<17:29,  3.36s/it]\n",
            "LE-03-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   1%|▏         | 4/315 [00:14<19:38,  3.79s/it]\n",
            "LE-03-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   2%|▏         | 5/315 [00:17<17:38,  3.41s/it]\n",
            "LE-03-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   2%|▏         | 6/315 [00:20<16:28,  3.20s/it]\n",
            "LE-03-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   2%|▏         | 7/315 [00:23<15:43,  3.06s/it]\n",
            "LE-03-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   3%|▎         | 8/315 [00:26<16:38,  3.25s/it]\n",
            "LE-03-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   3%|▎         | 9/315 [00:30<16:57,  3.33s/it]\n",
            "LE-03-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   3%|▎         | 10/315 [00:34<17:31,  3.45s/it]\n",
            "LE-03-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   3%|▎         | 11/315 [00:37<17:07,  3.38s/it]\n",
            "LG-02-Slide08_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   4%|▍         | 12/315 [00:39<15:43,  3.11s/it]\n",
            "LG-02-Slide08_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   4%|▍         | 13/315 [00:42<15:06,  3.00s/it]\n",
            "LG-02-Slide08_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   4%|▍         | 14/315 [00:44<13:00,  2.59s/it]\n",
            "LG-02-Slide09_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   5%|▍         | 15/315 [00:47<13:39,  2.73s/it]\n",
            "LG-02-Slide09_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   5%|▌         | 16/315 [00:49<13:34,  2.73s/it]\n",
            "LG-03-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   5%|▌         | 17/315 [00:52<12:55,  2.60s/it]\n",
            "LG-03-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   6%|▌         | 18/315 [00:55<13:58,  2.82s/it]\n",
            "LG-03-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   6%|▌         | 19/315 [00:57<13:12,  2.68s/it]\n",
            "LG-03-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   6%|▋         | 20/315 [00:59<11:53,  2.42s/it]\n",
            "LG-03-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   7%|▋         | 21/315 [01:01<11:18,  2.31s/it]\n",
            "LG-03-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   7%|▋         | 22/315 [01:03<11:10,  2.29s/it]\n",
            "LG-03-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   7%|▋         | 23/315 [01:07<12:22,  2.54s/it]\n",
            "LG-03-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   8%|▊         | 24/315 [01:09<11:32,  2.38s/it]\n",
            "LG-03-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   8%|▊         | 25/315 [01:11<11:08,  2.31s/it]\n",
            "LG-03-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   8%|▊         | 26/315 [01:13<11:32,  2.40s/it]\n",
            "LG-03-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   9%|▊         | 27/315 [01:15<10:50,  2.26s/it]\n",
            "LG-20-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   9%|▉         | 28/315 [01:18<10:58,  2.29s/it]\n",
            "LG-20-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   9%|▉         | 29/315 [01:20<11:11,  2.35s/it]\n",
            "LG-20-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  10%|▉         | 30/315 [01:23<11:24,  2.40s/it]\n",
            "LG-22-Slide08_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  10%|▉         | 31/315 [01:25<10:40,  2.26s/it]\n",
            "LG-22-Slide08_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  10%|█         | 32/315 [01:26<10:05,  2.14s/it]\n",
            "LG-22-Slide08_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  10%|█         | 33/315 [01:28<09:33,  2.03s/it]\n",
            "LG-22-Slide09_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  11%|█         | 34/315 [01:30<09:03,  1.93s/it]\n",
            "LG-22-Slide09_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  11%|█         | 35/315 [01:32<08:59,  1.93s/it]\n",
            "LG-22-Slide09_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  11%|█▏        | 36/315 [01:34<08:46,  1.89s/it]\n",
            "LG-22-Slide10_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  12%|█▏        | 37/315 [01:35<08:28,  1.83s/it]\n",
            "LG-22-Slide10_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  12%|█▏        | 38/315 [01:37<08:22,  1.81s/it]\n",
            "LG-22-Slide10_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  12%|█▏        | 39/315 [01:39<08:19,  1.81s/it]\n",
            "LG-22-Slide11_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  13%|█▎        | 40/315 [01:41<08:11,  1.79s/it]\n",
            "LG-22-Slide11_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  13%|█▎        | 41/315 [01:42<08:06,  1.77s/it]\n",
            "LG-22-Slide11_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  13%|█▎        | 42/315 [01:44<07:57,  1.75s/it]\n",
            "LG-22-Slide12_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  14%|█▎        | 43/315 [01:46<07:46,  1.72s/it]\n",
            "LG-22-Slide12_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  14%|█▍        | 44/315 [01:47<07:32,  1.67s/it]\n",
            "LG-22-Slide12_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  14%|█▍        | 45/315 [01:49<07:12,  1.60s/it]\n",
            "LG-23-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  15%|█▍        | 46/315 [01:51<07:32,  1.68s/it]\n",
            "LG-23-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  15%|█▍        | 47/315 [01:52<07:39,  1.72s/it]\n",
            "LG-23-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  15%|█▌        | 48/315 [01:54<07:35,  1.71s/it]\n",
            "LG-23-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  16%|█▌        | 49/315 [01:56<07:38,  1.72s/it]\n",
            "LG-25-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  16%|█▌        | 50/315 [01:58<07:37,  1.73s/it]\n",
            "LG-25-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  16%|█▌        | 51/315 [01:59<07:49,  1.78s/it]\n",
            "LG-25-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  17%|█▋        | 52/315 [02:02<08:56,  2.04s/it]\n",
            "LG-25-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  17%|█▋        | 53/315 [02:04<08:43,  2.00s/it]\n",
            "LG-25-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  17%|█▋        | 54/315 [02:06<08:34,  1.97s/it]\n",
            "LG-25-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  17%|█▋        | 55/315 [02:08<08:38,  1.99s/it]\n",
            "LG-25-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  18%|█▊        | 56/315 [02:10<08:45,  2.03s/it]\n",
            "LG-25-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  18%|█▊        | 57/315 [02:12<08:51,  2.06s/it]\n",
            "LG-26-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  18%|█▊        | 58/315 [02:14<08:03,  1.88s/it]\n",
            "LG-26-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  19%|█▊        | 59/315 [02:15<07:48,  1.83s/it]\n",
            "LG-26-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  19%|█▉        | 60/315 [02:17<06:52,  1.62s/it]\n",
            "LG-26-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  19%|█▉        | 61/315 [02:18<06:03,  1.43s/it]\n",
            "LG-26-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  20%|█▉        | 62/315 [02:19<05:28,  1.30s/it]\n",
            "LG-27-Slide08_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  20%|██        | 63/315 [02:20<06:09,  1.47s/it]\n",
            "LG-27-Slide08_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  20%|██        | 64/315 [02:22<06:21,  1.52s/it]\n",
            "LG-27-Slide08_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  21%|██        | 65/315 [02:25<07:53,  1.90s/it]\n",
            "LG-27-Slide09_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  21%|██        | 66/315 [02:26<07:31,  1.81s/it]\n",
            "LG-27-Slide09_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  21%|██▏       | 67/315 [02:28<07:09,  1.73s/it]\n",
            "LG-27-Slide09_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  22%|██▏       | 68/315 [02:30<06:59,  1.70s/it]\n",
            "LG-27-Slide10_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  22%|██▏       | 69/315 [02:32<08:21,  2.04s/it]\n",
            "LG-27-Slide10_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  22%|██▏       | 70/315 [02:34<07:54,  1.94s/it]\n",
            "LG-27-Slide10_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  23%|██▎       | 71/315 [02:36<07:27,  1.83s/it]\n",
            "LG-27-Slide11_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  23%|██▎       | 72/315 [02:37<07:07,  1.76s/it]\n",
            "LG-27-Slide11_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  23%|██▎       | 73/315 [02:39<06:52,  1.70s/it]\n",
            "LG-27-Slide11_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  23%|██▎       | 74/315 [02:40<06:43,  1.68s/it]\n",
            "LG-27-Slide12_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  24%|██▍       | 75/315 [02:42<06:34,  1.65s/it]\n",
            "LG-27-Slide12_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  24%|██▍       | 76/315 [02:44<06:32,  1.64s/it]\n",
            "LG-27-Slide12_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  24%|██▍       | 77/315 [02:45<06:23,  1.61s/it]\n",
            "LG-36-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  25%|██▍       | 78/315 [02:47<06:41,  1.69s/it]\n",
            "LG-36-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  25%|██▌       | 79/315 [02:50<07:35,  1.93s/it]\n",
            "LG-36-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  25%|██▌       | 80/315 [02:51<07:25,  1.90s/it]\n",
            "LG-36-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  26%|██▌       | 81/315 [02:53<07:24,  1.90s/it]\n",
            "LG-36-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  26%|██▌       | 82/315 [02:55<07:14,  1.87s/it]\n",
            "LG-36-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  26%|██▋       | 83/315 [02:57<07:38,  1.98s/it]\n",
            "LG-36-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  27%|██▋       | 84/315 [02:59<07:25,  1.93s/it]\n",
            "LG-36-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  27%|██▋       | 85/315 [03:01<07:16,  1.90s/it]\n",
            "LG-36-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  27%|██▋       | 86/315 [03:03<07:08,  1.87s/it]\n",
            "LG-36-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  28%|██▊       | 87/315 [03:04<06:50,  1.80s/it]\n",
            "LG-36-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  28%|██▊       | 88/315 [03:07<07:47,  2.06s/it]\n",
            "LG-36-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  28%|██▊       | 89/315 [03:09<07:09,  1.90s/it]\n",
            "LG-36-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  29%|██▊       | 90/315 [03:10<06:35,  1.76s/it]\n",
            "LG-36-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  29%|██▉       | 91/315 [03:11<06:04,  1.63s/it]\n",
            "LG-37-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  29%|██▉       | 92/315 [03:13<05:42,  1.54s/it]\n",
            "LG-37-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  30%|██▉       | 93/315 [03:14<05:34,  1.51s/it]\n",
            "LG-37-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  30%|██▉       | 94/315 [03:16<05:26,  1.48s/it]\n",
            "LG-37-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  30%|███       | 95/315 [03:17<05:33,  1.52s/it]\n",
            "LG-37-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  30%|███       | 96/315 [03:19<05:48,  1.59s/it]\n",
            "LG-37-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  31%|███       | 97/315 [03:21<06:07,  1.69s/it]\n",
            "LG-37-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  31%|███       | 98/315 [03:23<06:18,  1.74s/it]\n",
            "LG-37-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  31%|███▏      | 99/315 [03:25<06:28,  1.80s/it]\n",
            "LG-37-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  32%|███▏      | 100/315 [03:27<07:26,  2.08s/it]\n",
            "LG-37-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  32%|███▏      | 101/315 [03:29<07:13,  2.03s/it]\n",
            "LG-37-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  32%|███▏      | 102/315 [03:31<07:03,  1.99s/it]\n",
            "LG-37-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  33%|███▎      | 103/315 [03:33<06:49,  1.93s/it]\n",
            "LG-37-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  33%|███▎      | 104/315 [03:35<06:43,  1.91s/it]\n",
            "LG-39-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  33%|███▎      | 105/315 [03:37<06:58,  1.99s/it]\n",
            "LG-39-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  34%|███▎      | 106/315 [03:39<07:07,  2.05s/it]\n",
            "LG-39-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  34%|███▍      | 107/315 [03:41<07:12,  2.08s/it]\n",
            "LG-44-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  34%|███▍      | 108/315 [03:43<06:21,  1.84s/it]\n",
            "LG-44-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  35%|███▍      | 109/315 [03:45<07:12,  2.10s/it]\n",
            "LG-44-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  35%|███▍      | 110/315 [03:47<06:33,  1.92s/it]\n",
            "LG-44-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  35%|███▌      | 111/315 [03:48<06:15,  1.84s/it]\n",
            "LG-44-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  36%|███▌      | 112/315 [03:50<06:10,  1.82s/it]\n",
            "LG-44-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  36%|███▌      | 113/315 [03:52<06:08,  1.82s/it]\n",
            "LG-44-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  36%|███▌      | 114/315 [03:54<06:00,  1.79s/it]\n",
            "LG-44-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  37%|███▋      | 115/315 [03:56<06:01,  1.81s/it]\n",
            "LG-44-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  37%|███▋      | 116/315 [03:57<06:01,  1.82s/it]\n",
            "LG-44-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  37%|███▋      | 117/315 [03:59<06:05,  1.85s/it]\n",
            "LG-62-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  37%|███▋      | 118/315 [04:02<06:30,  1.98s/it]\n",
            "LG-62-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  38%|███▊      | 119/315 [04:03<05:56,  1.82s/it]\n",
            "LG-62-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  38%|███▊      | 120/315 [04:05<05:28,  1.68s/it]\n",
            "LG-62-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  38%|███▊      | 121/315 [04:06<05:09,  1.60s/it]\n",
            "LG-62-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  39%|███▊      | 122/315 [04:07<04:54,  1.52s/it]\n",
            "LG-62-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  39%|███▉      | 123/315 [04:09<04:40,  1.46s/it]\n",
            "LG-63-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  39%|███▉      | 124/315 [04:11<05:07,  1.61s/it]\n",
            "LG-63-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  40%|███▉      | 125/315 [04:12<05:25,  1.71s/it]\n",
            "LG-63-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  40%|████      | 126/315 [04:15<05:41,  1.81s/it]\n",
            "LG-63-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  40%|████      | 127/315 [04:17<05:51,  1.87s/it]\n",
            "LG-63-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  41%|████      | 128/315 [04:18<05:55,  1.90s/it]\n",
            "LG-63-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  41%|████      | 129/315 [04:22<07:01,  2.27s/it]\n",
            "LG-63-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  41%|████▏     | 130/315 [04:24<06:43,  2.18s/it]\n",
            "LG-63-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  42%|████▏     | 131/315 [04:26<06:26,  2.10s/it]\n",
            "LG-63-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  42%|████▏     | 132/315 [04:27<06:18,  2.07s/it]\n",
            "LG-63-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  42%|████▏     | 133/315 [04:29<06:09,  2.03s/it]\n",
            "LG-63-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  43%|████▎     | 134/315 [04:31<06:03,  2.01s/it]\n",
            "LG-63-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  43%|████▎     | 135/315 [04:33<05:54,  1.97s/it]\n",
            "LG-63-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  43%|████▎     | 136/315 [04:35<05:50,  1.96s/it]\n",
            "LG-63-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  43%|████▎     | 137/315 [04:37<05:51,  1.98s/it]\n",
            "LG-63-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  44%|████▍     | 138/315 [04:39<05:44,  1.94s/it]\n",
            "LG-64-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  44%|████▍     | 139/315 [04:40<04:58,  1.70s/it]\n",
            "LG-64-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  44%|████▍     | 140/315 [04:41<04:35,  1.57s/it]\n",
            "LG-64-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  45%|████▍     | 141/315 [04:43<04:19,  1.49s/it]\n",
            "LG-64-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  45%|████▌     | 142/315 [04:44<04:14,  1.47s/it]\n",
            "LG-64-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  45%|████▌     | 143/315 [04:46<04:13,  1.47s/it]\n",
            "LG-64-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  46%|████▌     | 144/315 [04:47<04:14,  1.49s/it]\n",
            "LG-64-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  46%|████▌     | 145/315 [04:49<04:17,  1.52s/it]\n",
            "LG-64-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  46%|████▋     | 146/315 [04:51<05:16,  1.87s/it]\n",
            "LG-64-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  47%|████▋     | 147/315 [04:53<05:05,  1.82s/it]\n",
            "LG-64-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  47%|████▋     | 148/315 [04:55<04:58,  1.79s/it]\n",
            "LG-64-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  47%|████▋     | 149/315 [04:57<04:57,  1.79s/it]\n",
            "LG-64-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  48%|████▊     | 150/315 [04:58<04:54,  1.78s/it]\n",
            "LG-64-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  48%|████▊     | 151/315 [05:00<04:52,  1.78s/it]\n",
            "LG-64-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  48%|████▊     | 152/315 [05:02<04:48,  1.77s/it]\n",
            "LG-64-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  49%|████▊     | 153/315 [05:04<04:47,  1.78s/it]\n",
            "LG-65-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  49%|████▉     | 154/315 [05:05<04:42,  1.76s/it]\n",
            "LG-65-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  49%|████▉     | 155/315 [05:07<04:45,  1.78s/it]\n",
            "LG-65-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  50%|████▉     | 156/315 [05:10<05:43,  2.16s/it]\n",
            "LG-65-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  50%|████▉     | 157/315 [05:12<05:37,  2.14s/it]\n",
            "LG-65-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  50%|█████     | 158/315 [05:15<05:33,  2.13s/it]\n",
            "LG-65-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  50%|█████     | 159/315 [05:18<06:13,  2.39s/it]\n",
            "LG-65-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  51%|█████     | 160/315 [05:20<06:02,  2.34s/it]\n",
            "LG-65-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  51%|█████     | 161/315 [05:22<05:59,  2.34s/it]\n",
            "LG-65-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  51%|█████▏    | 162/315 [05:24<05:53,  2.31s/it]\n",
            "LG-65-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  52%|█████▏    | 163/315 [05:27<05:43,  2.26s/it]\n",
            "LG-65-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  52%|█████▏    | 164/315 [05:29<05:35,  2.22s/it]\n",
            "LG-65-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  52%|█████▏    | 165/315 [05:31<05:29,  2.19s/it]\n",
            "LG-66-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  53%|█████▎    | 166/315 [05:33<05:05,  2.05s/it]\n",
            "LG-66-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  53%|█████▎    | 167/315 [05:34<04:54,  1.99s/it]\n",
            "LG-66-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  53%|█████▎    | 168/315 [05:36<04:43,  1.93s/it]\n",
            "LG-66-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  54%|█████▎    | 169/315 [05:38<04:37,  1.90s/it]\n",
            "LG-66-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  54%|█████▍    | 170/315 [05:40<04:34,  1.89s/it]\n",
            "LG-66-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  54%|█████▍    | 171/315 [05:42<04:30,  1.88s/it]\n",
            "LG-66-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  55%|█████▍    | 172/315 [05:44<04:27,  1.87s/it]\n",
            "LG-66-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  55%|█████▍    | 173/315 [05:45<04:25,  1.87s/it]\n",
            "LG-66-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  55%|█████▌    | 174/315 [05:47<04:20,  1.85s/it]\n",
            "LG-66-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  56%|█████▌    | 175/315 [05:49<04:18,  1.85s/it]\n",
            "LG-66-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  56%|█████▌    | 176/315 [05:51<04:09,  1.80s/it]\n",
            "LG-67-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  56%|█████▌    | 177/315 [05:54<04:56,  2.15s/it]\n",
            "LG-67-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  57%|█████▋    | 178/315 [05:56<04:41,  2.06s/it]\n",
            "LG-67-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  57%|█████▋    | 179/315 [05:57<04:32,  2.01s/it]\n",
            "LG-67-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  57%|█████▋    | 180/315 [05:59<04:22,  1.95s/it]\n",
            "LG-67-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  57%|█████▋    | 181/315 [06:02<05:03,  2.27s/it]\n",
            "LG-67-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  58%|█████▊    | 182/315 [06:04<04:47,  2.16s/it]\n",
            "LG-67-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  58%|█████▊    | 183/315 [06:06<04:34,  2.08s/it]\n",
            "LG-67-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  58%|█████▊    | 184/315 [06:08<04:28,  2.05s/it]\n",
            "LG-69-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  59%|█████▊    | 185/315 [06:10<04:04,  1.88s/it]\n",
            "LG-69-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  59%|█████▉    | 186/315 [06:11<03:50,  1.79s/it]\n",
            "LG-69-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  59%|█████▉    | 187/315 [06:13<03:45,  1.76s/it]\n",
            "LG-69-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  60%|█████▉    | 188/315 [06:15<03:44,  1.77s/it]\n",
            "LG-69-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  60%|██████    | 189/315 [06:17<03:48,  1.81s/it]\n",
            "LG-69-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  60%|██████    | 190/315 [06:20<04:33,  2.19s/it]\n",
            "LG-69-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  61%|██████    | 191/315 [06:22<04:23,  2.12s/it]\n",
            "LG-69-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  61%|██████    | 192/315 [06:23<04:12,  2.05s/it]\n",
            "LG-69-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  61%|██████▏   | 193/315 [06:25<04:07,  2.03s/it]\n",
            "LG-69-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  62%|██████▏   | 194/315 [06:28<04:27,  2.21s/it]\n",
            "LG-69-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  62%|██████▏   | 195/315 [06:30<04:16,  2.14s/it]\n",
            "LG-69-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  62%|██████▏   | 196/315 [06:32<04:09,  2.10s/it]\n",
            "LG-69-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  63%|██████▎   | 197/315 [06:35<04:30,  2.29s/it]\n",
            "LG-70-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  63%|██████▎   | 198/315 [06:37<04:29,  2.30s/it]\n",
            "LG-70-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  63%|██████▎   | 199/315 [06:39<04:24,  2.28s/it]\n",
            "LG-70-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  63%|██████▎   | 200/315 [06:42<04:45,  2.48s/it]\n",
            "LG-71-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  64%|██████▍   | 201/315 [06:44<04:21,  2.30s/it]\n",
            "LG-71-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  64%|██████▍   | 202/315 [06:46<04:06,  2.18s/it]\n",
            "LG-71-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  64%|██████▍   | 203/315 [06:48<03:56,  2.11s/it]\n",
            "LG-71-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  65%|██████▍   | 204/315 [06:50<03:51,  2.09s/it]\n",
            "LG-71-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  65%|██████▌   | 205/315 [06:52<03:44,  2.04s/it]\n",
            "LG-71-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  65%|██████▌   | 206/315 [06:54<03:28,  1.91s/it]\n",
            "LG-71-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  66%|██████▌   | 207/315 [06:55<03:15,  1.81s/it]\n",
            "LG-71-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  66%|██████▌   | 208/315 [06:57<03:13,  1.81s/it]\n",
            "LG-71-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  66%|██████▋   | 209/315 [06:59<03:04,  1.74s/it]\n",
            "LG-71-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  67%|██████▋   | 210/315 [07:00<02:56,  1.68s/it]\n",
            "LG-71-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  67%|██████▋   | 211/315 [07:01<02:40,  1.54s/it]\n",
            "LG-71-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  67%|██████▋   | 212/315 [07:02<02:22,  1.38s/it]\n",
            "LG-72-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  68%|██████▊   | 213/315 [07:04<02:17,  1.35s/it]\n",
            "LG-72-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  68%|██████▊   | 214/315 [07:05<02:15,  1.34s/it]\n",
            "LG-72-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  68%|██████▊   | 215/315 [07:06<02:12,  1.33s/it]\n",
            "LG-72-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  69%|██████▊   | 216/315 [07:08<02:13,  1.35s/it]\n",
            "LG-72-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  69%|██████▉   | 217/315 [07:09<02:16,  1.39s/it]\n",
            "LG-72-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  69%|██████▉   | 218/315 [07:11<02:21,  1.46s/it]\n",
            "LG-72-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  70%|██████▉   | 219/315 [07:12<02:27,  1.54s/it]\n",
            "LG-72-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  70%|██████▉   | 220/315 [07:15<03:03,  1.93s/it]\n",
            "LG-72-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  70%|███████   | 221/315 [07:17<02:56,  1.88s/it]\n",
            "LG-72-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  70%|███████   | 222/315 [07:19<02:49,  1.82s/it]\n",
            "LG-72-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  71%|███████   | 223/315 [07:20<02:46,  1.81s/it]\n",
            "LG-72-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  71%|███████   | 224/315 [07:22<02:41,  1.78s/it]\n",
            "LG-72-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  71%|███████▏  | 225/315 [07:24<02:37,  1.75s/it]\n",
            "LG-72-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  72%|███████▏  | 226/315 [07:26<02:36,  1.76s/it]\n",
            "LG-72-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  72%|███████▏  | 227/315 [07:27<02:36,  1.78s/it]\n",
            "LG-73-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  72%|███████▏  | 228/315 [07:29<02:40,  1.85s/it]\n",
            "LG-73-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  73%|███████▎  | 229/315 [07:31<02:40,  1.87s/it]\n",
            "LG-73-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  73%|███████▎  | 230/315 [07:33<02:31,  1.78s/it]\n",
            "LG-78-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  73%|███████▎  | 231/315 [07:35<02:31,  1.80s/it]\n",
            "LG-78-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  74%|███████▎  | 232/315 [07:37<02:31,  1.83s/it]\n",
            "LG-78-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  74%|███████▍  | 233/315 [07:39<02:29,  1.82s/it]\n",
            "LG-78-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  74%|███████▍  | 234/315 [07:40<02:26,  1.80s/it]\n",
            "LG-78-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  75%|███████▍  | 235/315 [07:42<02:24,  1.80s/it]\n",
            "LG-78-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  75%|███████▍  | 236/315 [07:44<02:21,  1.80s/it]\n",
            "LG-78-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  75%|███████▌  | 237/315 [07:45<02:16,  1.75s/it]\n",
            "LG-78-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  76%|███████▌  | 238/315 [07:47<02:13,  1.73s/it]\n",
            "LG-78-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  76%|███████▌  | 239/315 [07:49<02:08,  1.70s/it]\n",
            "LG-78-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  76%|███████▌  | 240/315 [07:50<02:04,  1.66s/it]\n",
            "LG-78-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  77%|███████▋  | 241/315 [07:52<01:59,  1.62s/it]\n",
            "LG-78-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  77%|███████▋  | 242/315 [07:53<01:54,  1.57s/it]\n",
            "LG-78-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  77%|███████▋  | 243/315 [07:55<01:49,  1.52s/it]\n",
            "LG-78-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  77%|███████▋  | 244/315 [07:56<01:43,  1.46s/it]\n",
            "LG-81-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  78%|███████▊  | 245/315 [07:59<02:20,  2.00s/it]\n",
            "LG-81-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  78%|███████▊  | 246/315 [08:02<02:22,  2.07s/it]\n",
            "LG-81-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  78%|███████▊  | 247/315 [08:04<02:23,  2.10s/it]\n",
            "LG-83-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  79%|███████▊  | 248/315 [08:05<02:13,  1.99s/it]\n",
            "LG-83-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  79%|███████▉  | 249/315 [08:07<02:07,  1.93s/it]\n",
            "LG-83-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  79%|███████▉  | 250/315 [08:09<02:03,  1.90s/it]\n",
            "LG-83-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  80%|███████▉  | 251/315 [08:11<01:58,  1.85s/it]\n",
            "LG-83-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  80%|████████  | 252/315 [08:13<01:56,  1.85s/it]\n",
            "LG-83-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  80%|████████  | 253/315 [08:15<01:57,  1.89s/it]\n",
            "LG-83-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  81%|████████  | 254/315 [08:17<01:57,  1.92s/it]\n",
            "LG-83-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  81%|████████  | 255/315 [08:19<01:58,  1.97s/it]\n",
            "LG-83-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  81%|████████▏ | 256/315 [08:22<02:12,  2.25s/it]\n",
            "LG-83-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  82%|████████▏ | 257/315 [08:24<02:08,  2.22s/it]\n",
            "LG-83-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  82%|████████▏ | 258/315 [08:26<02:13,  2.33s/it]\n",
            "LG-84-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  82%|████████▏ | 259/315 [08:28<02:04,  2.22s/it]\n",
            "LG-84-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  83%|████████▎ | 260/315 [08:30<01:57,  2.14s/it]\n",
            "LG-84-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  83%|████████▎ | 261/315 [08:32<01:51,  2.06s/it]\n",
            "LG-84-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  83%|████████▎ | 262/315 [08:34<01:52,  2.11s/it]\n",
            "LG-84-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  83%|████████▎ | 263/315 [08:36<01:44,  2.01s/it]\n",
            "LG-84-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  84%|████████▍ | 264/315 [08:38<01:38,  1.94s/it]\n",
            "LGC-12-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  84%|████████▍ | 265/315 [08:40<01:42,  2.05s/it]\n",
            "LGC-12-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  84%|████████▍ | 266/315 [08:43<01:54,  2.33s/it]\n",
            "LGC-12-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  85%|████████▍ | 267/315 [08:46<01:52,  2.33s/it]\n",
            "LGC-12-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  85%|████████▌ | 268/315 [08:48<01:48,  2.30s/it]\n",
            "LGC-12-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  85%|████████▌ | 269/315 [08:50<01:45,  2.30s/it]\n",
            "LGC-12-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  86%|████████▌ | 270/315 [08:52<01:42,  2.28s/it]\n",
            "LGC-12-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  86%|████████▌ | 271/315 [08:55<01:38,  2.25s/it]\n",
            "LGC-16-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  86%|████████▋ | 272/315 [08:57<01:37,  2.26s/it]\n",
            "LGC-16-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  87%|████████▋ | 273/315 [08:59<01:34,  2.25s/it]\n",
            "LGC-16-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  87%|████████▋ | 274/315 [09:01<01:32,  2.26s/it]\n",
            "LGC-16-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  87%|████████▋ | 275/315 [09:04<01:31,  2.28s/it]\n",
            "LGC-16-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  88%|████████▊ | 276/315 [09:06<01:29,  2.29s/it]\n",
            "LGC-16-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  88%|████████▊ | 277/315 [09:08<01:29,  2.35s/it]\n",
            "LGC-16-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  88%|████████▊ | 278/315 [09:11<01:25,  2.30s/it]\n",
            "LGC-16-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  89%|████████▊ | 279/315 [09:13<01:21,  2.26s/it]\n",
            "LGC-16-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  89%|████████▉ | 280/315 [09:15<01:18,  2.26s/it]\n",
            "LGC-16-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  89%|████████▉ | 281/315 [09:17<01:16,  2.24s/it]\n",
            "LGC-16-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  90%|████████▉ | 282/315 [09:19<01:13,  2.22s/it]\n",
            "LGC-16-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  90%|████████▉ | 283/315 [09:21<01:06,  2.09s/it]\n",
            "LGC-16-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  90%|█████████ | 284/315 [09:23<01:04,  2.09s/it]\n",
            "LGC-16-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  90%|█████████ | 285/315 [09:25<00:59,  2.00s/it]\n",
            "LGC-16-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  91%|█████████ | 286/315 [09:27<00:53,  1.84s/it]\n",
            "LGC-46-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  91%|█████████ | 287/315 [09:29<01:00,  2.15s/it]\n",
            "LGC-46-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  91%|█████████▏| 288/315 [09:31<00:54,  2.03s/it]\n",
            "LGC-46-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  92%|█████████▏| 289/315 [09:33<00:50,  1.95s/it]\n",
            "LGC-46-Slide04_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  92%|█████████▏| 290/315 [09:36<00:56,  2.26s/it]\n",
            "LGC-46-Slide04_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  92%|█████████▏| 291/315 [09:38<00:52,  2.18s/it]\n",
            "LGC-46-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  93%|█████████▎| 292/315 [09:40<00:49,  2.14s/it]\n",
            "LGC-46-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  93%|█████████▎| 293/315 [09:42<00:46,  2.11s/it]\n",
            "LGC-46-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  93%|█████████▎| 294/315 [09:44<00:43,  2.08s/it]\n",
            "LGC-46-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  94%|█████████▎| 295/315 [09:46<00:41,  2.07s/it]\n",
            "LGC-46-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  94%|█████████▍| 296/315 [09:48<00:38,  2.03s/it]\n",
            "LGC-46-Slide06_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  94%|█████████▍| 297/315 [09:50<00:36,  2.02s/it]\n",
            "LGC-46-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  95%|█████████▍| 298/315 [09:53<00:38,  2.26s/it]\n",
            "LGC-46-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  95%|█████████▍| 299/315 [09:55<00:34,  2.17s/it]\n",
            "LGC-46-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  95%|█████████▌| 300/315 [09:57<00:31,  2.08s/it]\n",
            "LGC-46-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  96%|█████████▌| 301/315 [09:58<00:28,  2.02s/it]\n",
            "LGC-56-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  96%|█████████▌| 302/315 [10:00<00:25,  1.95s/it]\n",
            "LGC-56-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  96%|█████████▌| 303/315 [10:02<00:23,  1.95s/it]\n",
            "LGC-56-Slide07_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  97%|█████████▋| 304/315 [10:04<00:21,  1.97s/it]\n",
            "LGC-58-Slide03_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  97%|█████████▋| 305/315 [10:06<00:19,  1.96s/it]\n",
            "LGC-58-Slide03_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  97%|█████████▋| 306/315 [10:08<00:17,  1.89s/it]\n",
            "LGC-58-Slide03_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  97%|█████████▋| 307/315 [10:10<00:15,  1.88s/it]\n",
            "LGC-58-Slide04_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  98%|█████████▊| 308/315 [10:12<00:12,  1.85s/it]\n",
            "LGC-58-Slide05_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  98%|█████████▊| 309/315 [10:13<00:10,  1.82s/it]\n",
            "LGC-58-Slide05_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  98%|█████████▊| 310/315 [10:15<00:09,  1.81s/it]\n",
            "LGC-58-Slide05_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  99%|█████████▊| 311/315 [10:17<00:07,  1.79s/it]\n",
            "LGC-58-Slide06_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  99%|█████████▉| 312/315 [10:19<00:05,  1.82s/it]\n",
            "LGC-58-Slide06_Section03_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  99%|█████████▉| 313/315 [10:21<00:03,  1.85s/it]\n",
            "LGC-58-Slide07_Section01_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides: 100%|█████████▉| 314/315 [10:22<00:01,  1.85s/it]\n",
            "LGC-58-Slide07_Section02_yp0_patch01_real_B_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                                         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken:  624.917300045 seconds\n",
            "0\n",
            "{}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# Extracting patch image features\n",
        "he_image_folder = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Good Real H&E images'\n",
        "he_feature_folder = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Good Real H&E features'\n",
        "extract_patch_emb(he_image_folder, he_feature_folder, '.png') # extracting (n x 768)D h&e image embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "SuElmEciUHVY",
        "outputId": "84160c3f-3d08-421d-9f26-39315c59b0ca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'histogpt_teacher' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4181821810.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extracting slide image embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhe_feature_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Good Real H&E features/h5_files/128px_ctranspath_0.0mpp_1.0xdown_normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhe_slide_emb_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_slide_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhe_feature_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogpt_teacher\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# extracting slide H&E emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhe_slide_emb_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhe_slide_emb_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'histogpt_teacher' is not defined"
          ]
        }
      ],
      "source": [
        "# Extracting slide image embeddings\n",
        "he_feature_folder = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Good Real H&E features/h5_files/128px_ctranspath_0.0mpp_1.0xdown_normal'\n",
        "he_slide_emb_dict = extract_slide_emb(he_feature_folder, histogpt_teacher) # extracting slide H&E emb\n",
        "print(len(he_slide_emb_dict))\n",
        "print(he_slide_emb_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt-zlgZaM9Uj",
        "outputId": "ce60faa4-1480-4dab-cfe9-c908ad70fb29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "slides:   0%|          | 0/315 [00:00<?, ?it/s]\n",
            "LE-03-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   0%|          | 1/315 [00:02<13:10,  2.52s/it]\n",
            "LE-03-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   1%|          | 2/315 [00:03<08:38,  1.66s/it]\n",
            "LE-03-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   1%|          | 3/315 [00:04<07:08,  1.37s/it]\n",
            "LE-03-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   1%|▏         | 4/315 [00:06<07:20,  1.42s/it]\n",
            "LE-03-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   2%|▏         | 5/315 [00:07<06:48,  1.32s/it]\n",
            "LE-03-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   2%|▏         | 6/315 [00:08<06:18,  1.23s/it]\n",
            "LE-03-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   2%|▏         | 7/315 [00:09<06:01,  1.17s/it]\n",
            "LE-03-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   3%|▎         | 8/315 [00:10<05:50,  1.14s/it]\n",
            "LE-03-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   3%|▎         | 9/315 [00:11<05:41,  1.12s/it]\n",
            "LE-03-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   3%|▎         | 10/315 [00:12<05:35,  1.10s/it]\n",
            "LE-03-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   3%|▎         | 11/315 [00:13<05:30,  1.09s/it]\n",
            "LG-02-Slide08_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   4%|▍         | 12/315 [00:14<05:04,  1.00s/it]\n",
            "LG-02-Slide08_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   4%|▍         | 13/315 [00:15<04:46,  1.05it/s]\n",
            "LG-02-Slide08_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   4%|▍         | 14/315 [00:16<04:30,  1.11it/s]\n",
            "LG-02-Slide09_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   5%|▍         | 15/315 [00:16<04:21,  1.15it/s]\n",
            "LG-02-Slide09_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   5%|▌         | 16/315 [00:17<04:14,  1.18it/s]\n",
            "LG-03-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   5%|▌         | 17/315 [00:18<04:29,  1.10it/s]\n",
            "LG-03-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   6%|▌         | 18/315 [00:19<04:39,  1.06it/s]\n",
            "LG-03-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   6%|▌         | 19/315 [00:20<04:46,  1.03it/s]\n",
            "LG-03-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   6%|▋         | 20/315 [00:21<04:37,  1.06it/s]\n",
            "LG-03-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   7%|▋         | 21/315 [00:22<04:31,  1.08it/s]\n",
            "LG-03-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   7%|▋         | 22/315 [00:23<04:34,  1.07it/s]\n",
            "LG-03-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   7%|▋         | 23/315 [00:24<04:40,  1.04it/s]\n",
            "LG-03-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   8%|▊         | 24/315 [00:25<04:35,  1.05it/s]\n",
            "LG-03-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   8%|▊         | 25/315 [00:26<04:31,  1.07it/s]\n",
            "LG-03-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   8%|▊         | 26/315 [00:27<04:26,  1.09it/s]\n",
            "LG-03-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   9%|▊         | 27/315 [00:28<04:23,  1.09it/s]\n",
            "LG-20-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   9%|▉         | 28/315 [00:29<04:35,  1.04it/s]\n",
            "LG-20-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:   9%|▉         | 29/315 [00:30<04:49,  1.01s/it]\n",
            "LG-20-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  10%|▉         | 30/315 [00:31<04:55,  1.04s/it]\n",
            "LG-22-Slide08_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  10%|▉         | 31/315 [00:32<04:41,  1.01it/s]\n",
            "LG-22-Slide08_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  10%|█         | 32/315 [00:33<04:31,  1.04it/s]\n",
            "LG-22-Slide08_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  10%|█         | 33/315 [00:33<04:20,  1.08it/s]\n",
            "LG-22-Slide09_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  11%|█         | 34/315 [00:34<04:10,  1.12it/s]\n",
            "LG-22-Slide09_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  11%|█         | 35/315 [00:35<04:07,  1.13it/s]\n",
            "LG-22-Slide09_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  11%|█▏        | 36/315 [00:36<04:00,  1.16it/s]\n",
            "LG-22-Slide10_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  12%|█▏        | 37/315 [00:37<03:52,  1.20it/s]\n",
            "LG-22-Slide10_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  12%|█▏        | 38/315 [00:38<03:48,  1.21it/s]\n",
            "LG-22-Slide10_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  12%|█▏        | 39/315 [00:38<03:48,  1.21it/s]\n",
            "LG-22-Slide11_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  13%|█▎        | 40/315 [00:39<03:48,  1.20it/s]\n",
            "LG-22-Slide11_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  13%|█▎        | 41/315 [00:40<03:47,  1.20it/s]\n",
            "LG-22-Slide11_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  13%|█▎        | 42/315 [00:41<03:44,  1.21it/s]\n",
            "LG-22-Slide12_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  14%|█▎        | 43/315 [00:42<03:42,  1.22it/s]\n",
            "LG-22-Slide12_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  14%|█▍        | 44/315 [00:42<03:38,  1.24it/s]\n",
            "LG-22-Slide12_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  14%|█▍        | 45/315 [00:43<03:34,  1.26it/s]\n",
            "LG-23-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  15%|█▍        | 46/315 [00:44<03:41,  1.22it/s]\n",
            "LG-23-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  15%|█▍        | 47/315 [00:45<03:39,  1.22it/s]\n",
            "LG-23-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  15%|█▌        | 48/315 [00:46<03:36,  1.23it/s]\n",
            "LG-23-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  16%|█▌        | 49/315 [00:47<03:36,  1.23it/s]\n",
            "LG-25-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  16%|█▌        | 50/315 [00:47<03:29,  1.27it/s]\n",
            "LG-25-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  16%|█▌        | 51/315 [00:48<03:27,  1.27it/s]\n",
            "LG-25-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  17%|█▋        | 52/315 [00:49<03:24,  1.29it/s]\n",
            "LG-25-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  17%|█▋        | 53/315 [00:50<03:20,  1.31it/s]\n",
            "LG-25-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  17%|█▋        | 54/315 [00:50<03:19,  1.31it/s]\n",
            "LG-25-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  17%|█▋        | 55/315 [00:51<03:22,  1.29it/s]\n",
            "LG-25-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  18%|█▊        | 56/315 [00:52<03:27,  1.25it/s]\n",
            "LG-25-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  18%|█▊        | 57/315 [00:53<03:31,  1.22it/s]\n",
            "LG-26-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  18%|█▊        | 58/315 [00:54<03:27,  1.24it/s]\n",
            "LG-26-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  19%|█▊        | 59/315 [00:54<03:23,  1.26it/s]\n",
            "LG-26-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  19%|█▉        | 60/315 [00:55<03:15,  1.30it/s]\n",
            "LG-26-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  19%|█▉        | 61/315 [00:56<03:08,  1.35it/s]\n",
            "LG-26-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  20%|█▉        | 62/315 [00:56<03:01,  1.39it/s]\n",
            "LG-27-Slide08_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  20%|██        | 63/315 [00:57<03:12,  1.31it/s]\n",
            "LG-27-Slide08_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  20%|██        | 64/315 [00:58<03:16,  1.28it/s]\n",
            "LG-27-Slide08_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  21%|██        | 65/315 [00:59<03:20,  1.25it/s]\n",
            "LG-27-Slide09_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  21%|██        | 66/315 [01:00<03:20,  1.24it/s]\n",
            "LG-27-Slide09_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  21%|██▏       | 67/315 [01:01<03:19,  1.24it/s]\n",
            "LG-27-Slide09_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  22%|██▏       | 68/315 [01:01<03:20,  1.23it/s]\n",
            "LG-27-Slide10_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  22%|██▏       | 69/315 [01:02<03:26,  1.19it/s]\n",
            "LG-27-Slide10_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  22%|██▏       | 70/315 [01:03<03:27,  1.18it/s]\n",
            "LG-27-Slide10_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  23%|██▎       | 71/315 [01:04<03:26,  1.18it/s]\n",
            "LG-27-Slide11_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  23%|██▎       | 72/315 [01:05<03:22,  1.20it/s]\n",
            "LG-27-Slide11_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  23%|██▎       | 73/315 [01:06<03:22,  1.19it/s]\n",
            "LG-27-Slide11_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  23%|██▎       | 74/315 [01:07<03:24,  1.18it/s]\n",
            "LG-27-Slide12_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  24%|██▍       | 75/315 [01:07<03:20,  1.20it/s]\n",
            "LG-27-Slide12_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  24%|██▍       | 76/315 [01:08<03:19,  1.20it/s]\n",
            "LG-27-Slide12_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  24%|██▍       | 77/315 [01:09<03:17,  1.21it/s]\n",
            "LG-36-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  25%|██▍       | 78/315 [01:10<03:14,  1.22it/s]\n",
            "LG-36-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  25%|██▌       | 79/315 [01:11<03:11,  1.23it/s]\n",
            "LG-36-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  25%|██▌       | 80/315 [01:11<03:10,  1.23it/s]\n",
            "LG-36-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  26%|██▌       | 81/315 [01:12<03:10,  1.23it/s]\n",
            "LG-36-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  26%|██▌       | 82/315 [01:13<03:07,  1.24it/s]\n",
            "LG-36-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  26%|██▋       | 83/315 [01:14<03:21,  1.15it/s]\n",
            "LG-36-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  27%|██▋       | 84/315 [01:15<03:17,  1.17it/s]\n",
            "LG-36-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  27%|██▋       | 85/315 [01:16<03:12,  1.19it/s]\n",
            "LG-36-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  27%|██▋       | 86/315 [01:16<03:09,  1.21it/s]\n",
            "LG-36-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  28%|██▊       | 87/315 [01:17<03:04,  1.23it/s]\n",
            "LG-36-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  28%|██▊       | 88/315 [01:18<03:00,  1.25it/s]\n",
            "LG-36-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  28%|██▊       | 89/315 [01:19<02:54,  1.29it/s]\n",
            "LG-36-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  29%|██▊       | 90/315 [01:19<02:49,  1.32it/s]\n",
            "LG-36-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  29%|██▉       | 91/315 [01:20<02:46,  1.35it/s]\n",
            "LG-37-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  29%|██▉       | 92/315 [01:21<02:45,  1.34it/s]\n",
            "LG-37-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  30%|██▉       | 93/315 [01:22<02:47,  1.32it/s]\n",
            "LG-37-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  30%|██▉       | 94/315 [01:22<02:48,  1.31it/s]\n",
            "LG-37-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  30%|███       | 95/315 [01:23<02:51,  1.28it/s]\n",
            "LG-37-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  30%|███       | 96/315 [01:24<02:58,  1.23it/s]\n",
            "LG-37-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  31%|███       | 97/315 [01:25<03:03,  1.19it/s]\n",
            "LG-37-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  31%|███       | 98/315 [01:26<03:09,  1.14it/s]\n",
            "LG-37-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  31%|███▏      | 99/315 [01:27<03:11,  1.13it/s]\n",
            "LG-37-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  32%|███▏      | 100/315 [01:28<03:13,  1.11it/s]\n",
            "LG-37-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  32%|███▏      | 101/315 [01:29<03:14,  1.10it/s]\n",
            "LG-37-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  32%|███▏      | 102/315 [01:30<03:13,  1.10it/s]\n",
            "LG-37-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  33%|███▎      | 103/315 [01:31<03:10,  1.11it/s]\n",
            "LG-37-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  33%|███▎      | 104/315 [01:31<03:09,  1.11it/s]\n",
            "LG-39-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  33%|███▎      | 105/315 [01:32<03:10,  1.10it/s]\n",
            "LG-39-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  34%|███▎      | 106/315 [01:33<03:09,  1.10it/s]\n",
            "LG-39-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  34%|███▍      | 107/315 [01:34<03:11,  1.08it/s]\n",
            "LG-44-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  34%|███▍      | 108/315 [01:35<02:59,  1.15it/s]\n",
            "LG-44-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  35%|███▍      | 109/315 [01:36<02:55,  1.18it/s]\n",
            "LG-44-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  35%|███▍      | 110/315 [01:37<02:46,  1.23it/s]\n",
            "LG-44-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  35%|███▌      | 111/315 [01:37<02:44,  1.24it/s]\n",
            "LG-44-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  36%|███▌      | 112/315 [01:38<02:43,  1.24it/s]\n",
            "LG-44-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  36%|███▌      | 113/315 [01:39<02:45,  1.22it/s]\n",
            "LG-44-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  36%|███▌      | 114/315 [01:40<02:44,  1.22it/s]\n",
            "LG-44-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  37%|███▋      | 115/315 [01:41<02:46,  1.20it/s]\n",
            "LG-44-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  37%|███▋      | 116/315 [01:41<02:46,  1.20it/s]\n",
            "LG-44-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  37%|███▋      | 117/315 [01:42<02:45,  1.19it/s]\n",
            "LG-62-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  37%|███▋      | 118/315 [01:43<02:38,  1.24it/s]\n",
            "LG-62-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  38%|███▊      | 119/315 [01:44<02:31,  1.29it/s]\n",
            "LG-62-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  38%|███▊      | 120/315 [01:44<02:25,  1.34it/s]\n",
            "LG-62-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  38%|███▊      | 121/315 [01:45<02:22,  1.36it/s]\n",
            "LG-62-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  39%|███▊      | 122/315 [01:46<02:19,  1.39it/s]\n",
            "LG-62-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  39%|███▉      | 123/315 [01:46<02:14,  1.43it/s]\n",
            "LG-63-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  39%|███▉      | 124/315 [01:47<02:20,  1.35it/s]\n",
            "LG-63-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  40%|███▉      | 125/315 [01:48<02:25,  1.31it/s]\n",
            "LG-63-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  40%|████      | 126/315 [01:49<02:28,  1.27it/s]\n",
            "LG-63-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  40%|████      | 127/315 [01:50<02:32,  1.23it/s]\n",
            "LG-63-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  41%|████      | 128/315 [01:51<02:34,  1.21it/s]\n",
            "LG-63-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  41%|████      | 129/315 [01:52<02:34,  1.20it/s]\n",
            "LG-63-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  41%|████▏     | 130/315 [01:52<02:33,  1.20it/s]\n",
            "LG-63-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  42%|████▏     | 131/315 [01:53<02:31,  1.22it/s]\n",
            "LG-63-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  42%|████▏     | 132/315 [01:54<02:29,  1.22it/s]\n",
            "LG-63-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  42%|████▏     | 133/315 [01:55<02:29,  1.22it/s]\n",
            "LG-63-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  43%|████▎     | 134/315 [01:56<02:30,  1.21it/s]\n",
            "LG-63-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  43%|████▎     | 135/315 [01:56<02:28,  1.21it/s]\n",
            "LG-63-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  43%|████▎     | 136/315 [01:57<02:29,  1.20it/s]\n",
            "LG-63-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  43%|████▎     | 137/315 [01:58<02:27,  1.20it/s]\n",
            "LG-63-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  44%|████▍     | 138/315 [01:59<02:26,  1.21it/s]\n",
            "LG-64-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  44%|████▍     | 139/315 [02:00<02:16,  1.29it/s]\n",
            "LG-64-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  44%|████▍     | 140/315 [02:00<02:10,  1.34it/s]\n",
            "LG-64-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  45%|████▍     | 141/315 [02:01<02:06,  1.37it/s]\n",
            "LG-64-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  45%|████▌     | 142/315 [02:02<02:04,  1.39it/s]\n",
            "LG-64-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  45%|████▌     | 143/315 [02:02<02:04,  1.38it/s]\n",
            "LG-64-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  46%|████▌     | 144/315 [02:03<02:04,  1.37it/s]\n",
            "LG-64-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  46%|████▌     | 145/315 [02:04<02:05,  1.36it/s]\n",
            "LG-64-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  46%|████▋     | 146/315 [02:05<02:03,  1.36it/s]\n",
            "LG-64-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  47%|████▋     | 147/315 [02:06<02:18,  1.21it/s]\n",
            "LG-64-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  47%|████▋     | 148/315 [02:07<02:16,  1.22it/s]\n",
            "LG-64-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  47%|████▋     | 149/315 [02:07<02:16,  1.22it/s]\n",
            "LG-64-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  48%|████▊     | 150/315 [02:08<02:13,  1.24it/s]\n",
            "LG-64-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  48%|████▊     | 151/315 [02:09<02:11,  1.25it/s]\n",
            "LG-64-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  48%|████▊     | 152/315 [02:10<02:08,  1.27it/s]\n",
            "LG-64-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  49%|████▊     | 153/315 [02:10<02:07,  1.27it/s]\n",
            "LG-65-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  49%|████▉     | 154/315 [02:11<02:06,  1.27it/s]\n",
            "LG-65-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  49%|████▉     | 155/315 [02:12<02:07,  1.26it/s]\n",
            "LG-65-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  50%|████▉     | 156/315 [02:13<02:08,  1.24it/s]\n",
            "LG-65-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  50%|████▉     | 157/315 [02:14<02:11,  1.21it/s]\n",
            "LG-65-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  50%|█████     | 158/315 [02:15<02:12,  1.19it/s]\n",
            "LG-65-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  50%|█████     | 159/315 [02:16<02:16,  1.14it/s]\n",
            "LG-65-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  51%|█████     | 160/315 [02:16<02:16,  1.14it/s]\n",
            "LG-65-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  51%|█████     | 161/315 [02:17<02:19,  1.11it/s]\n",
            "LG-65-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  51%|█████▏    | 162/315 [02:18<02:20,  1.09it/s]\n",
            "LG-65-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  52%|█████▏    | 163/315 [02:19<02:18,  1.10it/s]\n",
            "LG-65-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  52%|█████▏    | 164/315 [02:20<02:17,  1.10it/s]\n",
            "LG-65-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  52%|█████▏    | 165/315 [02:21<02:16,  1.10it/s]\n",
            "LG-66-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  53%|█████▎    | 166/315 [02:22<02:11,  1.14it/s]\n",
            "LG-66-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  53%|█████▎    | 167/315 [02:23<02:07,  1.16it/s]\n",
            "LG-66-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  53%|█████▎    | 168/315 [02:23<02:02,  1.20it/s]\n",
            "LG-66-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  54%|█████▎    | 169/315 [02:24<01:59,  1.22it/s]\n",
            "LG-66-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  54%|█████▍    | 170/315 [02:25<01:59,  1.22it/s]\n",
            "LG-66-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  54%|█████▍    | 171/315 [02:26<02:00,  1.19it/s]\n",
            "LG-66-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  55%|█████▍    | 172/315 [02:27<02:01,  1.17it/s]\n",
            "LG-66-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  55%|█████▍    | 173/315 [02:28<02:01,  1.17it/s]\n",
            "LG-66-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  55%|█████▌    | 174/315 [02:29<02:00,  1.17it/s]\n",
            "LG-66-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  56%|█████▌    | 175/315 [02:29<01:59,  1.17it/s]\n",
            "LG-66-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  56%|█████▌    | 176/315 [02:30<01:57,  1.18it/s]\n",
            "LG-67-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  56%|█████▌    | 177/315 [02:31<01:54,  1.20it/s]\n",
            "LG-67-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  57%|█████▋    | 178/315 [02:32<01:50,  1.24it/s]\n",
            "LG-67-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  57%|█████▋    | 179/315 [02:33<01:48,  1.25it/s]\n",
            "LG-67-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  57%|█████▋    | 180/315 [02:33<01:47,  1.26it/s]\n",
            "LG-67-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  57%|█████▋    | 181/315 [02:34<01:47,  1.25it/s]\n",
            "LG-67-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  58%|█████▊    | 182/315 [02:35<01:46,  1.25it/s]\n",
            "LG-67-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  58%|█████▊    | 183/315 [02:36<01:44,  1.26it/s]\n",
            "LG-67-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  58%|█████▊    | 184/315 [02:37<01:43,  1.26it/s]\n",
            "LG-69-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  59%|█████▊    | 185/315 [02:37<01:40,  1.29it/s]\n",
            "LG-69-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  59%|█████▉    | 186/315 [02:38<01:38,  1.32it/s]\n",
            "LG-69-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  59%|█████▉    | 187/315 [02:39<01:38,  1.30it/s]\n",
            "LG-69-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  60%|█████▉    | 188/315 [02:40<01:39,  1.27it/s]\n",
            "LG-69-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  60%|██████    | 189/315 [02:40<01:41,  1.25it/s]\n",
            "LG-69-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  60%|██████    | 190/315 [02:41<01:42,  1.22it/s]\n",
            "LG-69-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  61%|██████    | 191/315 [02:42<01:43,  1.20it/s]\n",
            "LG-69-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  61%|██████    | 192/315 [02:43<01:43,  1.19it/s]\n",
            "LG-69-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  61%|██████▏   | 193/315 [02:44<01:44,  1.17it/s]\n",
            "LG-69-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  62%|██████▏   | 194/315 [02:45<01:42,  1.18it/s]\n",
            "LG-69-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  62%|██████▏   | 195/315 [02:46<01:41,  1.18it/s]\n",
            "LG-69-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  62%|██████▏   | 196/315 [02:46<01:41,  1.17it/s]\n",
            "LG-69-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  63%|██████▎   | 197/315 [02:47<01:41,  1.16it/s]\n",
            "LG-70-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  63%|██████▎   | 198/315 [02:48<01:45,  1.11it/s]\n",
            "LG-70-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  63%|██████▎   | 199/315 [02:49<01:45,  1.09it/s]\n",
            "LG-70-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  63%|██████▎   | 200/315 [02:50<01:45,  1.09it/s]\n",
            "LG-71-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  64%|██████▍   | 201/315 [02:51<01:45,  1.08it/s]\n",
            "LG-71-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  64%|██████▍   | 202/315 [02:52<01:44,  1.08it/s]\n",
            "LG-71-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  64%|██████▍   | 203/315 [02:53<01:44,  1.07it/s]\n",
            "LG-71-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  65%|██████▍   | 204/315 [02:54<01:43,  1.07it/s]\n",
            "LG-71-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  65%|██████▌   | 205/315 [02:55<01:41,  1.08it/s]\n",
            "LG-71-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  65%|██████▌   | 206/315 [02:56<01:36,  1.13it/s]\n",
            "LG-71-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  66%|██████▌   | 207/315 [02:56<01:32,  1.17it/s]\n",
            "LG-71-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  66%|██████▌   | 208/315 [02:57<01:31,  1.17it/s]\n",
            "LG-71-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  66%|██████▋   | 209/315 [02:58<01:27,  1.20it/s]\n",
            "LG-71-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  67%|██████▋   | 210/315 [02:59<01:24,  1.25it/s]\n",
            "LG-71-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  67%|██████▋   | 211/315 [02:59<01:18,  1.32it/s]\n",
            "LG-71-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  67%|██████▋   | 212/315 [03:00<01:14,  1.38it/s]\n",
            "LG-72-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  68%|██████▊   | 213/315 [03:01<01:13,  1.39it/s]\n",
            "LG-72-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  68%|██████▊   | 214/315 [03:02<01:12,  1.40it/s]\n",
            "LG-72-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  68%|██████▊   | 215/315 [03:02<01:11,  1.41it/s]\n",
            "LG-72-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  69%|██████▊   | 216/315 [03:03<01:10,  1.40it/s]\n",
            "LG-72-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  69%|██████▉   | 217/315 [03:04<01:10,  1.38it/s]\n",
            "LG-72-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  69%|██████▉   | 218/315 [03:04<01:11,  1.36it/s]\n",
            "LG-72-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  70%|██████▉   | 219/315 [03:05<01:12,  1.33it/s]\n",
            "LG-72-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  70%|██████▉   | 220/315 [03:06<01:13,  1.30it/s]\n",
            "LG-72-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  70%|███████   | 221/315 [03:07<01:13,  1.28it/s]\n",
            "LG-72-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  70%|███████   | 222/315 [03:08<01:13,  1.27it/s]\n",
            "LG-72-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  71%|███████   | 223/315 [03:09<01:13,  1.25it/s]\n",
            "LG-72-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  71%|███████   | 224/315 [03:09<01:12,  1.25it/s]\n",
            "LG-72-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  71%|███████▏  | 225/315 [03:10<01:12,  1.25it/s]\n",
            "LG-72-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  72%|███████▏  | 226/315 [03:11<01:12,  1.23it/s]\n",
            "LG-72-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  72%|███████▏  | 227/315 [03:12<01:12,  1.22it/s]\n",
            "LG-73-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  72%|███████▏  | 228/315 [03:13<01:14,  1.16it/s]\n",
            "LG-73-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  73%|███████▎  | 229/315 [03:14<01:14,  1.15it/s]\n",
            "LG-73-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  73%|███████▎  | 230/315 [03:14<01:12,  1.17it/s]\n",
            "LG-78-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  73%|███████▎  | 231/315 [03:15<01:11,  1.17it/s]\n",
            "LG-78-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  74%|███████▎  | 232/315 [03:16<01:12,  1.15it/s]\n",
            "LG-78-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  74%|███████▍  | 233/315 [03:17<01:10,  1.16it/s]\n",
            "LG-78-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  74%|███████▍  | 234/315 [03:18<01:09,  1.17it/s]\n",
            "LG-78-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  75%|███████▍  | 235/315 [03:19<01:08,  1.18it/s]\n",
            "LG-78-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  75%|███████▍  | 236/315 [03:20<01:06,  1.18it/s]\n",
            "LG-78-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  75%|███████▌  | 237/315 [03:20<01:05,  1.19it/s]\n",
            "LG-78-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  76%|███████▌  | 238/315 [03:21<01:03,  1.20it/s]\n",
            "LG-78-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  76%|███████▌  | 239/315 [03:22<01:02,  1.22it/s]\n",
            "LG-78-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  76%|███████▌  | 240/315 [03:23<01:00,  1.24it/s]\n",
            "LG-78-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  77%|███████▋  | 241/315 [03:24<00:58,  1.27it/s]\n",
            "LG-78-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  77%|███████▋  | 242/315 [03:24<00:56,  1.28it/s]\n",
            "LG-78-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  77%|███████▋  | 243/315 [03:25<00:55,  1.30it/s]\n",
            "LG-78-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  77%|███████▋  | 244/315 [03:26<00:53,  1.33it/s]\n",
            "LG-81-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  78%|███████▊  | 245/315 [03:27<00:57,  1.21it/s]\n",
            "LG-81-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  78%|███████▊  | 246/315 [03:28<01:00,  1.14it/s]\n",
            "LG-81-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  78%|███████▊  | 247/315 [03:29<01:01,  1.11it/s]\n",
            "LG-83-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  79%|███████▊  | 248/315 [03:29<00:57,  1.16it/s]\n",
            "LG-83-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  79%|███████▉  | 249/315 [03:30<00:55,  1.19it/s]\n",
            "LG-83-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  79%|███████▉  | 250/315 [03:31<00:53,  1.22it/s]\n",
            "LG-83-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  80%|███████▉  | 251/315 [03:32<00:50,  1.26it/s]\n",
            "LG-83-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  80%|████████  | 252/315 [03:33<00:52,  1.20it/s]\n",
            "LG-83-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  80%|████████  | 253/315 [03:33<00:51,  1.21it/s]\n",
            "LG-83-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  81%|████████  | 254/315 [03:34<00:50,  1.20it/s]\n",
            "LG-83-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  81%|████████  | 255/315 [03:35<00:50,  1.18it/s]\n",
            "LG-83-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  81%|████████▏ | 256/315 [03:36<00:50,  1.18it/s]\n",
            "LG-83-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  82%|████████▏ | 257/315 [03:37<00:49,  1.17it/s]\n",
            "LG-83-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  82%|████████▏ | 258/315 [03:38<00:51,  1.10it/s]\n",
            "LG-84-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  82%|████████▏ | 259/315 [03:39<00:50,  1.10it/s]\n",
            "LG-84-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  83%|████████▎ | 260/315 [03:40<00:49,  1.12it/s]\n",
            "LG-84-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  83%|████████▎ | 261/315 [03:41<00:47,  1.14it/s]\n",
            "LG-84-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  83%|████████▎ | 262/315 [03:41<00:45,  1.17it/s]\n",
            "LG-84-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  83%|████████▎ | 263/315 [03:42<00:43,  1.19it/s]\n",
            "LG-84-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  84%|████████▍ | 264/315 [03:43<00:42,  1.21it/s]\n",
            "LGC-12-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  84%|████████▍ | 265/315 [03:44<00:42,  1.18it/s]\n",
            "LGC-12-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  84%|████████▍ | 266/315 [03:45<00:42,  1.16it/s]\n",
            "LGC-12-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  85%|████████▍ | 267/315 [03:46<00:41,  1.15it/s]\n",
            "LGC-12-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  85%|████████▌ | 268/315 [03:47<00:40,  1.15it/s]\n",
            "LGC-12-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  85%|████████▌ | 269/315 [03:47<00:39,  1.15it/s]\n",
            "LGC-12-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  86%|████████▌ | 270/315 [03:48<00:39,  1.15it/s]\n",
            "LGC-12-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  86%|████████▌ | 271/315 [03:49<00:38,  1.15it/s]\n",
            "LGC-16-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  86%|████████▋ | 272/315 [03:50<00:39,  1.09it/s]\n",
            "LGC-16-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  87%|████████▋ | 273/315 [03:51<00:39,  1.06it/s]\n",
            "LGC-16-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  87%|████████▋ | 274/315 [03:52<00:39,  1.04it/s]\n",
            "LGC-16-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  87%|████████▋ | 275/315 [03:53<00:38,  1.03it/s]\n",
            "LGC-16-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  88%|████████▊ | 276/315 [03:54<00:38,  1.02it/s]\n",
            "LGC-16-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  88%|████████▊ | 277/315 [03:55<00:38,  1.01s/it]\n",
            "LGC-16-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  88%|████████▊ | 278/315 [03:56<00:36,  1.01it/s]\n",
            "LGC-16-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  89%|████████▊ | 279/315 [03:57<00:35,  1.02it/s]\n",
            "LGC-16-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  89%|████████▉ | 280/315 [03:58<00:34,  1.03it/s]\n",
            "LGC-16-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  89%|████████▉ | 281/315 [03:59<00:32,  1.03it/s]\n",
            "LGC-16-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  90%|████████▉ | 282/315 [04:00<00:32,  1.03it/s]\n",
            "LGC-16-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  90%|████████▉ | 283/315 [04:01<00:29,  1.07it/s]\n",
            "LGC-16-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  90%|█████████ | 284/315 [04:02<00:28,  1.08it/s]\n",
            "LGC-16-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  90%|█████████ | 285/315 [04:03<00:27,  1.11it/s]\n",
            "LGC-16-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  91%|█████████ | 286/315 [04:03<00:25,  1.15it/s]\n",
            "LGC-46-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  91%|█████████ | 287/315 [04:04<00:24,  1.15it/s]\n",
            "LGC-46-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  91%|█████████▏| 288/315 [04:05<00:23,  1.15it/s]\n",
            "LGC-46-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  92%|█████████▏| 289/315 [04:06<00:22,  1.15it/s]\n",
            "LGC-46-Slide04_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  92%|█████████▏| 290/315 [04:07<00:22,  1.12it/s]\n",
            "LGC-46-Slide04_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  92%|█████████▏| 291/315 [04:08<00:21,  1.10it/s]\n",
            "LGC-46-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  93%|█████████▎| 292/315 [04:09<00:24,  1.06s/it]\n",
            "LGC-46-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  93%|█████████▎| 293/315 [04:10<00:22,  1.03s/it]\n",
            "LGC-46-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  93%|█████████▎| 294/315 [04:11<00:21,  1.02s/it]\n",
            "LGC-46-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  94%|█████████▎| 295/315 [04:12<00:19,  1.00it/s]\n",
            "LGC-46-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  94%|█████████▍| 296/315 [04:13<00:18,  1.02it/s]\n",
            "LGC-46-Slide06_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  94%|█████████▍| 297/315 [04:14<00:17,  1.04it/s]\n",
            "LGC-46-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  95%|█████████▍| 298/315 [04:15<00:16,  1.04it/s]\n",
            "LGC-46-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  95%|█████████▍| 299/315 [04:16<00:15,  1.06it/s]\n",
            "LGC-46-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  95%|█████████▌| 300/315 [04:17<00:14,  1.07it/s]\n",
            "LGC-46-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  96%|█████████▌| 301/315 [04:18<00:13,  1.07it/s]\n",
            "LGC-56-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  96%|█████████▌| 302/315 [04:19<00:11,  1.12it/s]\n",
            "LGC-56-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  96%|█████████▌| 303/315 [04:19<00:10,  1.14it/s]\n",
            "LGC-56-Slide07_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  97%|█████████▋| 304/315 [04:20<00:09,  1.14it/s]\n",
            "LGC-58-Slide03_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  97%|█████████▋| 305/315 [04:21<00:09,  1.11it/s]\n",
            "LGC-58-Slide03_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  97%|█████████▋| 306/315 [04:22<00:07,  1.15it/s]\n",
            "LGC-58-Slide03_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  97%|█████████▋| 307/315 [04:23<00:06,  1.17it/s]\n",
            "LGC-58-Slide04_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  98%|█████████▊| 308/315 [04:24<00:05,  1.20it/s]\n",
            "LGC-58-Slide05_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  98%|█████████▊| 309/315 [04:24<00:04,  1.21it/s]\n",
            "LGC-58-Slide05_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  98%|█████████▊| 310/315 [04:25<00:04,  1.21it/s]\n",
            "LGC-58-Slide05_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  99%|█████████▊| 311/315 [04:26<00:03,  1.23it/s]\n",
            "LGC-58-Slide06_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  99%|█████████▉| 312/315 [04:27<00:02,  1.22it/s]\n",
            "LGC-58-Slide06_Section03_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides:  99%|█████████▉| 313/315 [04:28<00:01,  1.21it/s]\n",
            "LGC-58-Slide07_Section01_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "slides: 100%|█████████▉| 314/315 [04:29<00:00,  1.20it/s]\n",
            "LGC-58-Slide07_Section02_yp0_patch01_real_A_0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                                         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken:  269.987519163 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "oct_image_folder = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Good paired OCT images'\n",
        "converted_oct_folder = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Converted RGB OCT images'\n",
        "oct_feature_folder = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Good Pair OCT features'\n",
        "\n",
        "# converting oct images to 3 channel rgb images and save them in converted_oct_folder\n",
        "for image in os.listdir(oct_image_folder):\n",
        "  image_path = os.path.join(oct_image_folder, image)\n",
        "  save_path = os.path.join(converted_oct_folder, image)\n",
        "  convert_to_rgb(image_path, save_path)\n",
        "\n",
        "extract_patch_emb(converted_oct_folder, oct_feature_folder, '.png') # extracting (n x 768)D oct image embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from types import MethodType\n",
        "def perceiver_resampler_forward(self, x):\n",
        "      x = self.linear(x)\n",
        "\n",
        "      x = x.unsqueeze(1) if x.ndim == 3 else x\n",
        "      b, m, _, _ = x.size()\n",
        "\n",
        "      x = x + self.media_pos[:m]\n",
        "      latents = self.latents.repeat(b, m, 1, 1)\n",
        "\n",
        "      for attn, ffwn in self.layers:\n",
        "          latents = latents + attn(x, latents)\n",
        "          latents = latents + ffwn(latents)\n",
        "\n",
        "      return self.norm(latents)\n",
        "\n",
        "resampler = histogpt_student.histogpt.perceiver_resampler\n",
        "\n",
        "# Dynamically create a new forward function and added it as a method to resampler obj\n",
        "resampler.forward = MethodType(perceiver_resampler_forward, resampler)"
      ],
      "metadata": {
        "id": "cLIqD11fnAsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "s0bYT5WYh209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8bc09037-fd12-4159-8243-f50c5c139a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yml\n",
            "LE-03-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LE-03-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LE-03-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LE-03-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LE-03-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LE-03-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LE-03-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LE-03-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LE-03-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LE-03-Slide06_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LE-03-Slide06_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-02-Slide08_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-02-Slide08_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-02-Slide08_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-02-Slide09_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-02-Slide09_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide03_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide07_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-03-Slide07_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-20-Slide03_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-20-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-20-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide08_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide08_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide08_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide09_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide09_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide09_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide10_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide10_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide10_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide11_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide11_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide11_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide12_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide12_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-22-Slide12_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-23-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-23-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-23-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-23-Slide07_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-25-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-25-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-25-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-25-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-25-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-25-Slide06_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-25-Slide07_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-25-Slide07_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-26-Slide03_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-26-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-26-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-26-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-26-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide08_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide08_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide08_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide09_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide09_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide09_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide10_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide10_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide10_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide11_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide11_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide11_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide12_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide12_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-27-Slide12_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide06_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide06_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide07_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide07_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-36-Slide07_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide03_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide06_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide06_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide07_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide07_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-37-Slide07_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-39-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-39-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-39-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-44-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-44-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-44-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-44-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-44-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-44-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-44-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-44-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-44-Slide06_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-44-Slide06_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-62-Slide03_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-62-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-62-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-62-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-62-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-62-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide03_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide06_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide06_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide07_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide07_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-63-Slide07_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide03_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide06_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide06_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide07_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide07_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-64-Slide07_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide03_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide06_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide06_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide07_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-65-Slide07_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide03_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide06_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide06_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide07_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide07_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-66-Slide07_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-67-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-67-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-67-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-67-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-67-Slide05_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-67-Slide05_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-67-Slide05_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-67-Slide06_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-69-Slide03_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-69-Slide03_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-69-Slide04_Section01_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-69-Slide04_Section02_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-69-Slide04_Section03_yp0_patch01_real_A.h5\n",
            "torch.Size([1, 1, 640, 1536])\n",
            "torch.Size([1, 1, 640, 1024])\n",
            "\n",
            "LG-69-Slide05_Section01_yp0_patch01_real_A.h5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.88 MiB is free. Process 2908 has 79.30 GiB memory in use. Of the allocated memory 74.71 GiB is allocated by PyTorch, and 4.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-870201464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moct_feature_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Good Pair OCT features/h5_files/128px_ctranspath_0.0mpp_1.0xdown_normal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moct_slide_emb_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_slide_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moct_feature_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogpt_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# extracting slide oct emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1650453443.py\u001b[0m in \u001b[0;36mextract_slide_emb\u001b[0;34m(patch_feature_folder, model)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Perceiver resampler: [B, 1, 640, dim_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperceiver_resampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Exit gate maps to LM hidden size: [B, 1, 640, D_txt]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmedia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperceiver_exitgate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# what XATTN uses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/histogpt/models/histogpt.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mffwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mffwn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/flamingo_pytorch/flamingo_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, latents)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'... i d, ... j d  -> ... i j'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;31m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# or the user has disabled using opt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.88 MiB is free. Process 2908 has 79.30 GiB memory in use. Of the allocated memory 74.71 GiB is allocated by PyTorch, and 4.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "oct_feature_folder = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Good Pair OCT features/h5_files/128px_ctranspath_0.0mpp_1.0xdown_normal'\n",
        "oct_slide_emb_dict = extract_slide_emb(oct_feature_folder, histogpt_student)# extracting slide oct emb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iYU0lAv0BX0"
      },
      "source": [
        "### Implementing Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvdmgKGQz_w9"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "# def cosine_loss(student_emb, teacher_emb):\n",
        "#   return 1 - F.cosine_similarity(student_emb, teacher_emb, dim=1).mean()\n",
        "import torch.nn.functional as F\n",
        "def contrastive_ce(student_emb, teacher_emb, temp = 0.07):\n",
        "  '''\n",
        "  Contrastive cross-entropy loss (InfoNCE-style).\n",
        "  COmpares each student embedding to all teacher embeddings in the batch.\n",
        "  '''\n",
        "\n",
        "  # Normalize embeddings\n",
        "  student_emb = F.normalize(student_emb, dim=-1)\n",
        "  teacher_emb = F.normalize(teacher_emb, dim=-1)\n",
        "\n",
        "  # Compute similarity matrix: (batch_size, batch_size)\n",
        "  logits = torch.matmul(student_emb, teacher_emb.T)\n",
        "  logits /= temp # apply temp scaling\n",
        "\n",
        "  # Ground Truth: i-th student <-> i-th teacher\n",
        "  targets = torch.arange(logits.size(0), device=logits.device) # this tells that H&E correct match of ith OCT is in index i\n",
        "\n",
        "  # Compute cross entropy loss\n",
        "  loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "  return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKFPYSXnzxyJ"
      },
      "source": [
        "### Loading the saved model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0Kn3CUkz2Rq"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(student, teacher, optimizer, config, scheduler=None):\n",
        "  checkpoint_path = os.path.join(config['output_dir_path'], 'larger batch size 128','best_model.pth')\n",
        "\n",
        "  if os.path.exists(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    student.load_state_dict(checkpoint['student_state_dict'])\n",
        "\n",
        "    if teacher and checkpoint['teacher_state_dict']:\n",
        "      teacher.load_state_dict(checkpoint['teacher_state_dict'])\n",
        "\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    # Manually override the learning rate from the checkpoint\n",
        "    for param_group in optimizer.param_groups:\n",
        "      param_group['lr'] = config['init_lr']  # Or directly use 1e-5\n",
        "    print(f\"Learning rate reset to: {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "\n",
        "    if scheduler and checkpoint['scheduler_state_dict']:\n",
        "      scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    best_val_loss = checkpoint.get('val_loss', float('inf'))\n",
        "    print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
        "    print(f\"Best val loss: {best_val_loss}\")\n",
        "    return checkpoint['epoch'] + 1, best_val_loss # Resume from next epoch\n",
        "\n",
        "  else:\n",
        "    print(\"No checkpoint found. Starting from scratch.\")\n",
        "    return 0, float('inf')  # Start from epoch 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqcXiWLuzpr7"
      },
      "source": [
        "### Saving the trained model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zq8rUV7mzt_E"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(student, teacher, optimizer, epoch, config, scheduler=None, val_loss=None, filename='latest_checkpoint.pth'):\n",
        "  print('Saving to: ', config['output_dir_path'])\n",
        "  os.makedirs(config['output_dir_path'], exist_ok=True)\n",
        "\n",
        "  best_model_path = os.path.join(config['output_dir_path'], 'larger batch size 128', 'best_model_2.pth')\n",
        "  torch.save({\n",
        "      'epoch': epoch,\n",
        "      'student_state_dict': student.state_dict(),\n",
        "      'teacher_state_dict': teacher.state_dict() if teacher else None,\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "      'val_loss': val_loss\n",
        "  }, best_model_path)\n",
        "\n",
        "  print(f\"Saved checkpoint at epoch {epoch} with val_loss: {val_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjyaJGwC0MYy"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfISm18k0SlH"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# Filter parameters that require gradients\n",
        "# trainable_params = [p for p in student_model.parameters() if p.requires_grad]\n",
        "optimizer = Adam(student_model.parameters(), lr=train_config['init_lr'], weight_decay=train_config['weight_decay'])\n",
        "scheduler = ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',  # minimize val loss\n",
        "    factor=0.5,  # reduce LR by half\n",
        "    patience=1,  # wait 1 epochs of no improvement\n",
        "    threshold=1e-4, # minimum change to qualify as improvement\n",
        "    verbose=True # print LR changes\n",
        ")\n",
        "print(optimizer.param_groups[0]['lr'])\n",
        "print(optimizer.param_groups[0]['weight_decay'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGKEVUeTz51A"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter # for visualizing the loss\n",
        "\n",
        "writer = SummaryWriter(log_dir = 'runs/student_training_run')\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "def train_student(num_epochs, train_loader, he_val_loader, vhe_val_loader, student_model, teacher_model, optimizer, device, scheduler):\n",
        "\n",
        "  scaler = GradScaler()  # Needed for mixed precision\n",
        "\n",
        "  # for early stopping\n",
        "  epochs_without_improvement = 0\n",
        "  patience = train_config['patience']\n",
        "\n",
        "  # Load from checkpoint if available\n",
        "  start_epoch, best_val_loss = load_checkpoint(student_model, teacher_model, optimizer, train_config, scheduler)\n",
        "  # best_val_loss = float('inf')\n",
        "  # start_epoch = 0\n",
        "\n",
        "  ### Training Loop #####\n",
        "  for epoch in range(start_epoch, num_epochs):\n",
        "    student_model.train()  # student in train mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (oct_images, he_images) in enumerate(train_loader):\n",
        "      oct_images = oct_images.to(device)\n",
        "      he_images = he_images.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        teacher_emb = teacher_model(image=he_images, with_head=True, out_norm=True, ms_aug=False, return_global=True)[0]\n",
        "      teacher_emb = teacher_emb.detach()\n",
        "\n",
        "      with autocast(dtype=torch.float16):\n",
        "        student_emb = student_model(image=oct_images, with_head=True, out_norm=True, ms_aug=False, return_global=True)[0]\n",
        "        loss = contrastive_ce(student_emb, teacher_emb)\n",
        "        # print(f\"Student emb mean: {student_emb.mean().item():.4f}, Teacher emb mean: {teacher_emb.mean().item():.4f}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "        if torch.isnan(student_emb).any() or torch.isnan(teacher_emb).any():\n",
        "          print(f\"NaNs detected at batch {batch_idx+1}\")\n",
        "\n",
        "        if student_emb.abs().max() < 1e-6:\n",
        "          print(f\"Student embedding is close to zero at batch {batch_idx+1}\")\n",
        "\n",
        "      optimizer.zero_grad() # zero out gradient\n",
        "      scaler.scale(loss).backward() # backpropagation\n",
        "      scaler.unscale_(optimizer)\n",
        "      torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "      scaler.step(optimizer) # update parameters (weight & biases)\n",
        "      scaler.update()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      if (batch_idx + 1) % 15 == 0: # print the loss in every 100 batch in each epoch\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}] | Batch [{batch_idx + 1}/{len(train_loader)}] | Batch Loss: {loss.item():.4f}\")\n",
        "\n",
        "      # log the loss every 100 batches in each epoch\n",
        "      global_step = epoch * len(train_loader) + batch_idx\n",
        "      writer.add_scalar('Loss/train', loss.item(), global_step)\n",
        "\n",
        "    ### Training Loop ####\n",
        "\n",
        "    ### Printing average loss after each epoch ####\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}\")\n",
        "    # log average loss at the end of each epoch\n",
        "    writer.add_scalar(\"Loss/epoch_train\", average_loss, epoch)\n",
        "    # log learning rate to tensorboard\n",
        "    writer.add_scalar(\"Learning Rate\", optimizer.param_groups[0]['lr'], epoch)\n",
        "    ### Printing average loss after each epoch ####\n",
        "\n",
        "    torch.cuda.empty_cache()  # Clean memory after each epoch\n",
        "\n",
        "    ### Evaluate every 10 epochs with validation dataset ####\n",
        "    if (epoch + 1) % train_config['epochs_between_val'] == 0:\n",
        "      print(f\"Evaluating at epoch {epoch + 1}\")\n",
        "      student_model.eval() # evaluation mode\n",
        "      he_val_loss_total = 0\n",
        "      vhe_val_loss_total = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for oct_images, he_images in he_val_loader:\n",
        "          oct_images = oct_images.to(device)\n",
        "          he_images = he_images.to(device)\n",
        "\n",
        "          teacher_emb = teacher_model(image=he_images, with_head=True, out_norm=True, ms_aug=False, return_global=True)[0]\n",
        "          student_emb = student_model(image=oct_images, with_head=True, out_norm=True, ms_aug=False, return_global=True)[0]\n",
        "\n",
        "          val_loss = contrastive_ce(student_emb, teacher_emb)\n",
        "          he_val_loss_total += val_loss.item()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for oct_images, vhe_images in vhe_val_loader:\n",
        "          oct_images = oct_images.to(device)\n",
        "          vhe_images = vhe_images.to(device)\n",
        "\n",
        "          teacher_emb = teacher_model(image=vhe_images, with_head=True, out_norm=True, ms_aug=False, return_global=True)[0]\n",
        "          student_emb = student_model(image=oct_images, with_head=True, out_norm=True, ms_aug=False, return_global=True)[0]\n",
        "\n",
        "          val_loss = contrastive_ce(student_emb, teacher_emb)\n",
        "          vhe_val_loss_total += val_loss.item()\n",
        "\n",
        "      avg_he_val_loss = he_val_loss_total / len(he_val_loader)\n",
        "      avg_vhe_val_loss = vhe_val_loss_total / len(vhe_val_loader)\n",
        "\n",
        "      print(f\"Validation Loss (H&E) at Epoch {epoch + 1}: {avg_he_val_loss:.4f}\")\n",
        "      print(f\"Validation Loss (vH&E) at Epoch {epoch + 1}: {avg_vhe_val_loss:.4f}\")\n",
        "\n",
        "      avg_val_loss = (avg_he_val_loss + avg_vhe_val_loss) / 2\n",
        "      print(f\"Average Validation Loss at Epoch {epoch + 1}: {avg_val_loss:.4f}\")\n",
        "\n",
        "\n",
        "      scheduler.step(avg_val_loss) # update the learning rate\n",
        "      current_lr = optimizer.param_groups[0]['lr']\n",
        "      print(f\"Learning Rate after scheduler step: {current_lr}\")\n",
        "\n",
        "      torch.cuda.empty_cache()  # Clean memory after each epoch\n",
        "\n",
        "      if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss # update the curr avg val loss if the avg val loss is less than the prev avg val loss\n",
        "        print(f'New best val loss: {best_val_loss}')\n",
        "        epochs_without_improvement = 0\n",
        "        save_checkpoint(student_model, teacher_model, optimizer, epoch, train_config, scheduler, best_val_loss, filename=f\"best_model.pth\")\n",
        "\n",
        "      else:\n",
        "        epochs_without_improvement += 1\n",
        "\n",
        "      if epochs_without_improvement >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch + 1}\") # to prevent overfitting\n",
        "        break\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dtTQF9u0X1G"
      },
      "outputs": [],
      "source": [
        "train_student(\n",
        "    num_epochs=train_config['epochs'],\n",
        "    train_loader=train_loader,\n",
        "    he_val_loader=he_val_loader,\n",
        "    vhe_val_loader=vhe_val_loader,\n",
        "    student_model=histogpt_student,\n",
        "    teacher_model=histogpt_teacher,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    scheduler=scheduler\n",
        "  )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNLQf+De26y79On0JYVYfoV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}