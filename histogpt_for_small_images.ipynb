{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyileiaye2021/HistoGPT/blob/main/histogpt_for_small_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNcsz0DzGFuq"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADo3Kvc5tvM7"
      },
      "outputs": [],
      "source": [
        "# install openslide dependencies\n",
        "!sudo apt-get install openslide-tools\n",
        "!sudo apt-get install python-openslide\n",
        "!pip install openslide-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYnndg378hGy"
      },
      "outputs": [],
      "source": [
        "# install flamingo and histogpt\n",
        "!pip install flamingo-pytorch --no-deps\n",
        "!pip install git+https://github.com/marrlab/HistoGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKuH-u8KHDYX"
      },
      "outputs": [],
      "source": [
        "# check whether to use a gpu or cpu\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting the Google Drive"
      ],
      "metadata": {
        "id": "iUpkzICbGxxS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ktm3nzwmmgCv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziXj33E5GuCq"
      },
      "source": [
        "# Download model into Google Drive\n",
        "Change the drive file path to download the HistoGPT model and CTransPath image encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGt2WKLUH7GP"
      },
      "outputs": [],
      "source": [
        "# download small/medium histogpt weights\n",
        "# Already done if you've downloaded it and store it in google drive before\n",
        "!wget \"https://huggingface.co/marr-peng-lab/histogpt/resolve/main/histogpt-1b-6k-pruned.pth\" -O /content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Histogpt_weights/histogpt-1b-6k-pruned.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QccKDYWRbekV"
      },
      "outputs": [],
      "source": [
        "# download ctranspath weights\n",
        "# Already done if you've downloaded it and store it in google drive before\n",
        "!wget https://huggingface.co/marr-peng-lab/histogpt/resolve/main/ctranspath.pth?download=true -O /content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Ctranspath_weights/ctranspath.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvSqeS98NMxt"
      },
      "source": [
        "# Extract features\n",
        "Slide images are first made patches of the size 128. Then, features are extracted from each patch with CTransPath image encoder. Then, those features are concatenated as slide features and saved as part of .h5 files. For OCT images,since they are 1 channel images, we converted them to RGB 3 channel images to be able to use as input for HistoGPT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ziWydBgZxHc"
      },
      "outputs": [],
      "source": [
        "# patch and extract features (i don't think we need this. we already did uni encoding features)\n",
        "import os\n",
        "import shutil\n",
        "from histogpt.helpers.patching import main, PatchingConfigs\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# loading grayscale images\n",
        "grayscale_img = cv2.imread('/content/LHC-36-Slide07_Section01_yp0_A.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# converting the grayscale to rgb\n",
        "rgb_img = cv2.cvtColor(grayscale_img, cv2.COLOR_GRAY2RGB)\n",
        "saved_rgb_img_path = '/content/LHC-36-Slide07_Section01_yp0_A_converted.jpg' # saved rgb file path\n",
        "cv2.imwrite(saved_rgb_img_path, rgb_img)\n",
        "\n",
        "try:\n",
        "  os.mkdir('/content/slide_folder')\n",
        "  os.mkdir('/content/save_folder')\n",
        "  shutil.move(saved_rgb_img_path, \"/content/slide_folder/LHC-36-Slide07_Section01_yp0_A_converted.jpg\")\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "configs = PatchingConfigs()\n",
        "configs.slide_path = '/content/slide_folder' # '/content/drive/MyDrive/Teacher_Student_Network/Split Dataset/he_val/H&E'\n",
        "configs.save_path = '/content/save_folder' # '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Real H&E test dataset features'\n",
        "configs.file_extension = '.jpg'\n",
        "configs.model_path = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Ctranspath_weights/ctranspath.pth' # should be the image encoder weight (ctranspath used right now)\n",
        "configs.patch_size = 128\n",
        "configs.white_thresh = [170, 185, 175]\n",
        "configs.edge_threshold = 2\n",
        "configs.resolution_in_mpp = 0.0\n",
        "configs.downscaling_factor = 1.0\n",
        "# configs.save_patch_images = True\n",
        "configs.save_tile_preview = True\n",
        "configs.batch_size = 16\n",
        "# Use all slides in the folder\n",
        "configs.split = [0, 1]  # Use all files\n",
        "\n",
        "main(configs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPrf3xoxIBbg"
      },
      "source": [
        "# Generate reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8yzhRcy9Bue"
      },
      "outputs": [],
      "source": [
        "# configure histogpt and load weights\n",
        "from transformers import BioGptConfig\n",
        "from histogpt.models import HistoGPTForCausalLM, PerceiverResamplerConfig\n",
        "\n",
        "histogpt = HistoGPTForCausalLM(BioGptConfig(), PerceiverResamplerConfig())\n",
        "histogpt = histogpt.to(device)\n",
        "\n",
        "PATH = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Histogpt_weights/histogpt-1b-6k-pruned.pth' # histogpt weight\n",
        "state_dict = torch.load(PATH, map_location=device)\n",
        "histogpt.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "# with h5py.File('/content/save_folder/h5_files/64px_ctranspath_1.0mpp_1.0xdown_normal/LG-62-Slide03_Section01_yp0_B.h5', 'r') as f:\n",
        "#       features = f['feats'][:]\n",
        "#       features = torch.tensor(features).unsqueeze(0).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gagmnM5cJbCy"
      },
      "outputs": [],
      "source": [
        "# generate text autoregressively\n",
        "from histogpt.helpers.inference import generate\n",
        "\n",
        "def generate_text(histogpt, prompt, image_feature, tokenizer):\n",
        "  histogpt = histogpt.to(device)\n",
        "  prompt = prompt.to(device)\n",
        "  emb_tensor = features\n",
        "  output = generate(\n",
        "      model=histogpt,\n",
        "      prompt=prompt,\n",
        "      image=emb_tensor,\n",
        "      length=256,\n",
        "      top_k=40,\n",
        "      top_p=0.95,\n",
        "      temp=0.7,\n",
        "      device=device\n",
        "  )\n",
        "\n",
        "  decoded = tokenizer.decode(output[0, 1:])\n",
        "  return decoded\n",
        "\n",
        "# For generating consistent output for histogpt\n",
        "# def generate_text(histogpt, prompt, image_feature, tokenizer):\n",
        "#   histogpt = histogpt.to(device)\n",
        "#   prompt = prompt.to(device)\n",
        "#   emb_tensor = features\n",
        "#   output = generate(\n",
        "#       model=histogpt,\n",
        "#       prompt=prompt,\n",
        "#       image=emb_tensor,\n",
        "#       length=256,\n",
        "#       top_k=1,\n",
        "#       top_p=1.0,\n",
        "#       temp=0.1,\n",
        "#       device=device\n",
        "#   )\n",
        "\n",
        "#   decoded = tokenizer.decode(output[0, 1:])\n",
        "#   return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzP6-rlXUD6T"
      },
      "outputs": [],
      "source": [
        "# get text prompt and image features\n",
        "import os\n",
        "from PIL import Image\n",
        "import textwrap\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from transformers import BioGptTokenizer\n",
        "res = []\n",
        "res.append(('Image Path', 'HistoGPT Output (Prompt- Final Diagnosis:)'))\n",
        "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
        "\n",
        "# text prompt\n",
        "prompt = 'Final Diagnosis: '\n",
        "prompt = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device)\n",
        "\n",
        "feature_folder = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Real H&E test dataset features/h5_files/128px_ctranspath_0.0mpp_1.0xdown_normal'\n",
        "for h5_file in os.listdir(feature_folder):\n",
        "\n",
        "  # image features\n",
        "  if h5_file.endswith('.h5'):\n",
        "    filename = os.path.join(feature_folder, h5_file)\n",
        "    with h5py.File(filename, 'r') as f:\n",
        "      features = f['feats'][:]\n",
        "      features = torch.tensor(features).unsqueeze(0).to(device) # H&E image features\n",
        "\n",
        "    # generate text\n",
        "    decoded = generate_text(histogpt, prompt, features, tokenizer)\n",
        "    image_path = h5_file.replace('.h5', '.png')\n",
        "    image_path = os.path.join('/content/drive/MyDrive/Teacher_Student_Network/Split Dataset/he_val/H&E', image_path)\n",
        "    image = Image.open(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print(textwrap.fill(decoded, width=64))\n",
        "\n",
        "    # store the image paths and generated outputs\n",
        "    res.append((h5_file, decoded))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code checks if the features for the image file is extracted and created as .h5 file. It is similar function to the above code. But, it iterates thru the image files and find it is in .h5 folder as well."
      ],
      "metadata": {
        "id": "GrqPiwunIx8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterating thru image files and find it is in .h5 files as well\n",
        "# get text prompt and image features\n",
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import textwrap\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from transformers import BioGptTokenizer\n",
        "res = []\n",
        "res.append(('Image Path', 'HistoGPT Output (Prompt- Is there a basal cell carcinoma or basalioma?)'))\n",
        "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
        "\n",
        "# text prompt\n",
        "prompt = 'Is there a basal cell carcinoma?: '\n",
        "prompt = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device)\n",
        "\n",
        "feature_folder = Path('/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Real H&E test dataset features/h5_files/128px_ctranspath_0.0mpp_1.0xdown_normal')\n",
        "image_folder = Path('/content/drive/MyDrive/Teacher_Student_Network/Split Dataset/he_val/H&E')\n",
        "\n",
        "h5_folder = {p.stem.lower(): p for p in feature_folder.glob('*.h5')} # hashmap to iterate more efficiently\n",
        "# {.h5 filename without ext : .h5 full path}\n",
        "\n",
        "for image_path in image_folder.iterdir():\n",
        "\n",
        "  h5_file = image_path.stem.lower() # only image name with ext name stripped off\n",
        "\n",
        "  # some of the features are not generated. so we need to check which images have .h5 features.\n",
        "  if h5_file in h5_folder:\n",
        "    h5_path = h5_folder[h5_file]\n",
        "    with h5py.File(h5_path, 'r') as f:\n",
        "      features = f['feats'][:]\n",
        "      features = torch.tensor(features).unsqueeze(0).to(device) # H&E image features\n",
        "\n",
        "    # generate text\n",
        "    decoded = generate_text(histogpt, prompt, features, tokenizer)\n",
        "    image_path = os.path.join(image_folder, image_path)\n",
        "    image = Image.open(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print(textwrap.fill(decoded, width=64))\n",
        "\n",
        "    # store the image paths and generated outputs\n",
        "    res.append((h5_file, decoded))\n",
        "\n",
        "  # if there is no feature extracted for the image, we just add placeholder\n",
        "  else:\n",
        "    res.append((h5_file, \"Feature not extracted.\"))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tojw5PHhUn-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmmKFuRYMwx3"
      },
      "outputs": [],
      "source": [
        "# save the outputs in csv file\n",
        "import csv\n",
        "\n",
        "save_file = '/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/HistoGPT outputs.csv'\n",
        "with open(save_file, 'w', newline='') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerows(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For running histogpt for a single image"
      ],
      "metadata": {
        "id": "-MRusXpJZgTS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z33duVtvTKzj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# view image and print text\n",
        "# from openslide import OpenSlide\n",
        "from PIL import Image\n",
        "import textwrap\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from transformers import BioGptTokenizer\n",
        "\n",
        "jpg_path = \"/content/slide_folder/LHC-36-Slide07_Section01_yp0_A_converted.jpg\"\n",
        "image = Image.open(jpg_path)\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
        "print()\n",
        "# prompt = \"Final diagnosis:\"\n",
        "prompt = 'Is there a basal cell carcinoma or basalioma?: '\n",
        "prompt = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device)\n",
        "with h5py.File('/content/save_folder/h5_files/128px_ctranspath_0.0mpp_1.0xdown_normal/LHC-36-Slide07_Section01_yp0_A_converted.h5', 'r') as f:\n",
        "      features = f['feats'][:]\n",
        "      features = torch.tensor(features).unsqueeze(0).to(device)\n",
        "      print(features.shape)\n",
        "\n",
        "decoded = generate_text(histogpt, prompt, features, tokenizer)\n",
        "print(textwrap.fill(decoded, width=64))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Storing Good H&E Images in a folder"
      ],
      "metadata": {
        "id": "xOLLIyCPLqBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load csv file\n",
        "\n",
        "# iterate thru the image folder\n",
        "#   find if the curr image is in the csv file\n",
        "#     check if it is good\n",
        "#       store it in the new folder\n",
        "import os\n",
        "import csv\n",
        "import collections\n",
        "\n",
        "csv_map = collections.defaultdict(str)\n",
        "separated_csv_file = \"/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Test_Set_image_file_paths.csv\"\n",
        "all_image_path = \"/content/drive/MyDrive/Teacher_Student_Network/Split Dataset/he_val/H&E\"\n",
        "good_image_path = \"/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Good Real H&E images\"\n",
        "count = 0\n",
        "\n",
        "#### CREATE A DICT FOR CSV FILE TO EXTRACT ROWS AND COLS FROM CSV FILE EFFECTIVELY #####\n",
        "# read all rows in csv file and add the properties in a hashmap\n",
        "# hashmap = {filename: [(BCC or No BCC), (Good or Bad)]}\n",
        "with open(separated_csv_file, 'r') as f:\n",
        "  reader = csv.DictReader(f)\n",
        "\n",
        "  # for all other rows, add the filename and its properties in the dict\n",
        "  for row in reader:\n",
        "    filename = row['Image files']\n",
        "    label = row['Good or Bad Examples (Modified)']\n",
        "    csv_map[filename] = label\n",
        "    count += 1\n",
        "\n",
        "print(count)\n",
        "print(csv_map)\n",
        "\n",
        "##### MOVING GOOD IMGAES TO A NEW FOLDER TO GET CLEAN DATASET ######\n",
        "good_images_num = 0\n",
        "for filename in os.listdir(all_image_path):\n",
        "  if filename in csv_map:\n",
        "    if csv_map[filename] == 'Good':\n",
        "      shutil.copy(os.path.join(all_image_path, filename), good_image_path)\n",
        "      good_images_num += 1\n",
        "\n",
        "print(good_images_num)"
      ],
      "metadata": {
        "id": "NO49d1uIBHyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Storing Good OCT images in a folder"
      ],
      "metadata": {
        "id": "MnYflIYvbfqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oct_image_path = \"/content/drive/MyDrive/Teacher_Student_Network/Histo GPT/Good paired OCT images\"\n",
        "all_oct_image_path = \"/content/drive/MyDrive/Teacher_Student_Network/Split Dataset/he_val/OCT\"\n",
        "\n",
        "good_oct_images_num = 0\n",
        "for filename in os.listdir(all_oct_image_path):\n",
        "  basename, ext = os.path.splitext(filename)\n",
        "  basename = basename.replace(\"real_A\", \"real_B\")\n",
        "\n",
        "  oct_filename = basename + ext\n",
        "  if oct_filename in csv_map:\n",
        "    if csv_map[oct_filename] == 'Good':\n",
        "      shutil.copy(os.path.join(all_oct_image_path, filename), oct_image_path)\n",
        "      good_oct_images_num += 1\n",
        "\n",
        "print(good_oct_images_num)"
      ],
      "metadata": {
        "id": "coqxIzjwWK8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JW4ospDPel8z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}